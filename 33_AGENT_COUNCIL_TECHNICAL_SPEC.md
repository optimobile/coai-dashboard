# 33-Agent Council: Technical Specification

## Overview

The CSOAI 33-Agent Council is a **Byzantine fault-tolerant (BFT) voting system** that uses 33 independent AI agents to evaluate AI safety incidents, compliance assessments, and policy proposals. The system achieves consensus through distributed voting with a 2/3 majority requirement (22 out of 33 votes).

---

## Architecture

### Agent Composition

The council consists of **33 agents** distributed across three specialized types:

| Agent Type | Count | Role | Icon |
|------------|-------|------|------|
| **Guardian Agents** | 11 | Safety, Security, Privacy | üõ°Ô∏è |
| **Arbiter Agents** | 11 | Fairness, Transparency, Accountability | ‚öñÔ∏è |
| **Scribe Agents** | 11 | Documentation, Compliance, Reporting | üìÑ |

### Provider Distribution

Each agent type is distributed across three LLM providers for diversity:

- **OpenAI**: 4 agents per type (12 total)
- **Anthropic**: 4 agents per type (12 total)
- **Google**: 3 agents per type (9 total)

**Total: 33 agents** (11 √ó 3 types)

This multi-provider approach ensures:
- **Model diversity** (different training data, architectures, biases)
- **Fault tolerance** (if one provider fails, others continue)
- **Byzantine resistance** (no single provider can control consensus)

---

## Database Schema

### Council Sessions Table

```typescript
councilSessions {
  id: int (primary key)
  subjectType: enum ["watchdog_report", "assessment", "policy_proposal", "system_review"]
  subjectId: int (reference to subject being evaluated)
  subjectTitle: varchar(255)
  subjectDescription: text
  status: enum ["voting", "consensus_reached", "escalated_to_human", "completed"]
  consensusThreshold: decimal(5,2) default 0.67 // 67% = 22/33
  totalVotes: int default 0
  approveVotes: int default 0
  rejectVotes: int default 0
  escalateVotes: int default 0
  finalDecision: enum ["approved", "rejected", "escalated"]
  humanReviewerId: int (nullable)
  humanDecision: text (nullable)
  createdAt: timestamp
  completedAt: timestamp (nullable)
}
```

### Agent Votes Table

```typescript
agentVotes {
  id: int (primary key)
  sessionId: int (foreign key ‚Üí councilSessions.id)
  agentId: varchar(50) // e.g., "agent_1", "agent_2", etc.
  agentType: enum ["guardian", "arbiter", "scribe"]
  agentProvider: enum ["openai", "anthropic", "google"]
  vote: enum ["approve", "reject", "escalate"]
  confidence: decimal(5,2) // 0.00 to 1.00
  reasoning: text // Agent's explanation for the vote
  createdAt: timestamp
}
```

---

## Voting Process

### 1. Session Creation

When a Watchdog report is submitted or an assessment needs review:

```typescript
// Automatically create council session
await db.insert(councilSessions).values({
  subjectType: "watchdog_report",
  subjectId: reportId,
  subjectTitle: "Privacy violation in facial recognition system",
  subjectDescription: "Detailed incident description...",
  status: "voting",
});
```

### 2. Agent Generation

The `generateAgentCouncil()` function creates 33 unique agents:

```typescript
function generateAgentCouncil() {
  const agents = [];
  const types = ["guardian", "arbiter", "scribe"];
  const providers = ["openai", "anthropic", "google"];
  
  let agentNum = 1;
  for (const type of types) {
    for (let i = 0; i < 11; i++) {
      const provider = providers[i % 3]; // Rotate providers
      agents.push({
        id: `agent_${agentNum}`,
        name: `${capitalize(type)} Agent ${i + 1}`,
        type,
        provider
      });
      agentNum++;
    }
  }
  
  return agents; // Returns 33 agents
}
```

**Result:**
- Guardian Agent 1-11 (OpenAI, Anthropic, Google rotation)
- Arbiter Agent 1-11 (OpenAI, Anthropic, Google rotation)
- Scribe Agent 1-11 (OpenAI, Anthropic, Google rotation)

### 3. LLM Voting

Each agent independently evaluates the subject via LLM API:

```typescript
for (const agent of agents) {
  const response = await invokeLLM({
    messages: [
      {
        role: "system",
        content: `You are ${agent.name}, a ${agent.type} agent in the CSOAI 33-Agent Council. 
        Your role is to evaluate AI safety incidents and vote on appropriate actions. 
        You must respond with a JSON object containing: 
        vote ("approve", "reject", or "escalate"), 
        confidence (0-1), 
        and reasoning (brief explanation).`
      },
      {
        role: "user",
        content: `Please evaluate this incident and cast your vote:

Title: ${session.subjectTitle}
Description: ${session.subjectDescription}
Type: ${session.subjectType}

Respond with JSON only: 
{"vote": "approve|reject|escalate", "confidence": 0.0-1.0, "reasoning": "your brief reasoning"}`
      }
    ],
    response_format: {
      type: "json_schema",
      json_schema: {
        name: "agent_vote",
        strict: true,
        schema: {
          type: "object",
          properties: {
            vote: { type: "string", enum: ["approve", "reject", "escalate"] },
            confidence: { type: "number" },
            reasoning: { type: "string" }
          },
          required: ["vote", "confidence", "reasoning"],
          additionalProperties: false
        }
      }
    }
  });

  const parsed = JSON.parse(response.choices[0].message.content);
  votes.push({
    agentId: agent.id,
    agentType: agent.type,
    agentProvider: agent.provider,
    vote: parsed.vote,
    confidence: parsed.confidence,
    reasoning: parsed.reasoning
  });
}
```

**Key Features:**
- **Structured JSON output** (enforced by `json_schema`)
- **Agent-specific system prompts** (each agent knows its role)
- **Confidence scoring** (0.0 to 1.0)
- **Reasoning transparency** (every vote includes explanation)
- **Fallback handling** (if LLM fails, vote "escalate" with 0.5 confidence)

### 4. Vote Storage

All votes are stored in the database:

```typescript
for (const vote of votes) {
  await db.insert(agentVotes).values({
    sessionId: sessionId,
    agentId: vote.agentId,
    agentType: vote.agentType,
    agentProvider: vote.agentProvider,
    vote: vote.vote,
    confidence: vote.confidence.toString(),
    reasoning: vote.reasoning,
  });
}
```

### 5. Consensus Calculation

The system calculates consensus using **Byzantine fault-tolerant rules**:

```typescript
// Count votes
const approveCount = votes.filter(v => v.vote === "approve").length;
const rejectCount = votes.filter(v => v.vote === "reject").length;
const escalateCount = votes.filter(v => v.vote === "escalate").length;

// Consensus threshold: 2/3 majority = 22 out of 33
const consensusThreshold = 22;
let finalDecision: "approved" | "rejected" | "escalated" = "escalated";
let status: "consensus_reached" | "escalated_to_human" = "escalated_to_human";

if (approveCount >= consensusThreshold) {
  finalDecision = "approved";
  status = "consensus_reached";
} else if (rejectCount >= consensusThreshold) {
  finalDecision = "rejected";
  status = "consensus_reached";
}
// If neither reaches 22 votes, it's escalated to human review
```

**Consensus Rules:**
- **Approved**: ‚â•22 "approve" votes
- **Rejected**: ‚â•22 "reject" votes
- **Escalated**: <22 votes for any single option (requires human review)

### 6. Session Update

Final results are saved to the session:

```typescript
await db.update(councilSessions)
  .set({
    status,
    totalVotes: 33,
    approveVotes: approveCount,
    rejectVotes: rejectCount,
    escalateVotes: escalateCount,
    finalDecision,
    completedAt: new Date(),
  })
  .where(eq(councilSessions.id, sessionId));
```

---

## Transparency & Decision Tracking

### Public Access

All council sessions are **publicly accessible** via:

1. **Council Page** (`/council`)
   - Lists all voting sessions
   - Shows vote distribution (approve/reject/escalate)
   - Displays consensus status and final decision

2. **Public API** (`/api/publicApi.getCouncilDecisions`)
   - Returns council voting history
   - Includes vote counts and reasoning
   - Enables third-party transparency audits

3. **Public Dashboard** (`/public`)
   - Real-time council decision feed
   - Industry-wide consensus statistics

### Vote Transparency

Every vote includes:
- **Agent ID** (e.g., "agent_15")
- **Agent Type** (guardian/arbiter/scribe)
- **Provider** (OpenAI/Anthropic/Google)
- **Vote** (approve/reject/escalate)
- **Confidence** (0.0 to 1.0)
- **Reasoning** (text explanation)

This enables:
- **Audit trails** for regulatory compliance
- **Pattern analysis** (which agent types vote how)
- **Provider comparison** (do OpenAI agents vote differently than Anthropic?)
- **Confidence analysis** (high-confidence votes vs. uncertain votes)

---

## Byzantine Fault Tolerance

### Why 33 Agents?

The number 33 is chosen based on BFT principles:

- **Formula**: `n = 3f + 1` where `f` is the number of faulty nodes
- **For n=33**: Can tolerate up to `f = 10` faulty/malicious agents
- **Consensus**: Requires `2f + 1 = 21` honest votes (we use 22 for safety)

### Fault Scenarios

| Scenario | Faulty Agents | Honest Agents | Consensus Possible? |
|----------|---------------|---------------|---------------------|
| Normal | 0 | 33 | ‚úÖ Yes |
| Minor failure | 5 | 28 | ‚úÖ Yes (28 > 22) |
| Major failure | 10 | 23 | ‚úÖ Yes (23 > 22) |
| Byzantine attack | 11 | 22 | ‚ö†Ô∏è Borderline (22 = threshold) |
| System compromise | 12+ | <22 | ‚ùå No (escalate to human) |

### Attack Resistance

The system is resistant to:

1. **Single provider compromise**: Even if all OpenAI agents (12) are compromised, the remaining 21 agents cannot reach consensus alone.

2. **Agent type bias**: Even if all Guardian agents (11) vote maliciously, they cannot override the other 22 agents.

3. **Sybil attacks**: Agent identities are hardcoded and tied to specific LLM providers.

4. **Collusion**: Requires 12+ agents to collude, which is difficult given multi-provider distribution.

---

## Frontend Visualization

### Council Page Features

1. **Agent Group Cards**
   - Shows 3 agent types with counts
   - Lists provider distribution
   - Color-coded by role

2. **Voting Session List**
   - Real-time status updates
   - Vote distribution progress bars
   - Consensus threshold indicator (22/33)
   - Time-ago timestamps

3. **Vote Distribution Bars**
   ```
   Approve  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  18/33
   Reject   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   3/33
   Escalate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  12/33
   ```

4. **Status Badges**
   - üü¢ **Approved** (‚â•22 approve votes)
   - üî¥ **Rejected** (‚â•22 reject votes)
   - üü° **Escalated** (<22 votes for any option)
   - ‚è≥ **Voting** (in progress)

---

## API Endpoints

### Backend tRPC Routes

```typescript
council: {
  // Get all council sessions
  list: publicProcedure.query()
  
  // Get session with all votes
  getSession: publicProcedure.input({ id: number }).query()
  
  // Trigger 33-agent voting
  triggerVoting: protectedProcedure.input({ sessionId: number }).mutation()
  
  // Get council statistics
  getStats: publicProcedure.query()
}
```

### Response Format

**triggerVoting Response:**
```json
{
  "success": true,
  "totalVotes": 33,
  "approveVotes": 24,
  "rejectVotes": 5,
  "escalateVotes": 4,
  "finalDecision": "approved",
  "consensusReached": true
}
```

**getSession Response:**
```json
{
  "session": {
    "id": 1,
    "subjectTitle": "Privacy violation in facial recognition",
    "status": "consensus_reached",
    "finalDecision": "rejected",
    "approveVotes": 8,
    "rejectVotes": 23,
    "escalateVotes": 2
  },
  "votes": [
    {
      "agentId": "agent_1",
      "agentType": "guardian",
      "agentProvider": "openai",
      "vote": "reject",
      "confidence": "0.92",
      "reasoning": "System lacks adequate privacy safeguards for biometric data"
    },
    // ... 32 more votes
  ]
}
```

---

## Use Cases

### 1. Watchdog Report Review

When a public user submits a Watchdog report:
1. Report is created in database
2. Council session is automatically created
3. 33 agents vote on the incident severity
4. If consensus reached, report status is updated
5. If escalated, human analyst reviews

### 2. Compliance Assessment

When an AI system undergoes compliance assessment:
1. Assessment results are submitted
2. Council evaluates compliance level
3. Agents vote on approval/rejection
4. Company receives decision with reasoning

### 3. Policy Proposal

When a new AI safety policy is proposed:
1. Policy text is submitted to council
2. Agents evaluate from safety/fairness/compliance perspectives
3. Consensus determines policy adoption
4. Reasoning is published for transparency

---

## Testing

### Unit Tests

The council system has **34 tests** in `server/routers.test.ts`:

```typescript
describe("Council Router", () => {
  it("should list council sessions")
  it("should get session with votes")
  it("should trigger voting with consensus")
  it("should escalate when no consensus")
  it("should calculate statistics correctly")
  it("should handle LLM failures gracefully")
  // ... 28 more tests
});
```

### Test Coverage

- ‚úÖ Session creation
- ‚úÖ Vote recording
- ‚úÖ Consensus calculation
- ‚úÖ Escalation logic
- ‚úÖ Statistics aggregation
- ‚úÖ Error handling
- ‚úÖ Byzantine scenarios

---

## Performance Considerations

### Parallel Voting

Currently, agents vote **sequentially** (one after another). For production at scale, this can be optimized:

```typescript
// Parallel voting with Promise.all
const votePromises = agents.map(agent => 
  invokeLLM({ /* agent prompt */ })
);
const responses = await Promise.all(votePromises);
```

**Improvement**: 33 sequential LLM calls (~30 seconds) ‚Üí 33 parallel calls (~3 seconds)

### Caching

For identical subjects, votes can be cached:
- Hash the subject (title + description)
- Check if council has voted on identical subject before
- Return cached result if available

### Rate Limiting

LLM providers have rate limits:
- **OpenAI**: 500 requests/min (GPT-4)
- **Anthropic**: 50 requests/min (Claude)
- **Google**: 60 requests/min (Gemini)

Solution: Implement request queuing and retry logic.

---

## Future Enhancements

### 1. Weighted Voting

Assign different weights to agent types based on subject:
- **Safety incidents**: Guardian agents have 1.5x weight
- **Fairness issues**: Arbiter agents have 1.5x weight
- **Compliance audits**: Scribe agents have 1.5x weight

### 2. Confidence-Weighted Consensus

Factor in confidence scores:
- High-confidence votes (>0.8) count as 1.2 votes
- Low-confidence votes (<0.5) count as 0.8 votes

### 3. Agent Specialization

Create sub-specialties within each type:
- Guardian: Privacy, Security, Safety
- Arbiter: Fairness, Transparency, Accountability
- Scribe: Documentation, Compliance, Reporting

### 4. Human-in-the-Loop

When escalated, allow human reviewers to:
- See all 33 agent votes and reasoning
- Override consensus with justification
- Provide feedback to improve agent voting

### 5. Learning from History

Train agents on historical council decisions:
- Feed past votes as examples
- Improve consistency over time
- Reduce escalation rate

---

## Conclusion

The 33-Agent Council is a **production-ready Byzantine fault-tolerant voting system** that:

‚úÖ Uses 33 independent AI agents across 3 providers  
‚úÖ Achieves 2/3 majority consensus (22/33 votes)  
‚úÖ Stores all votes with reasoning for transparency  
‚úÖ Handles up to 10 faulty/malicious agents  
‚úÖ Escalates to human review when consensus fails  
‚úÖ Provides public API for transparency audits  
‚úÖ Has 34 passing unit tests  

This system forms the **core decision-making infrastructure** for CSOAI's AI governance platform.
