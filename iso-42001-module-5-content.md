# Support and Operations: Executing AI Management

## Introduction: From Planning to Action

Planning establishes what needs to be done. Support and operations make it happen. ISO 42001 Clauses 7 and 8 address the resources, competencies, processes, and controls needed to operationalize the AI Management System and manage AI systems throughout their lifecycle.

Clause 7 (Support) ensures the AIMS has necessary foundations: adequate resources, competent people, organizational awareness, effective communication, and comprehensive documentation. Without these support elements, even the best plans cannot be executed effectively.

Clause 8 (Operation) establishes requirements for operational planning and control of AI systems—the day-to-day processes and controls that ensure AI systems are developed, deployed, and operated in accordance with AIMS requirements. This is where risk management becomes real, where policies translate into practice, and where AI trustworthiness is actually achieved.

This module explores support and operational requirements in depth, providing practical guidance on building the capabilities and implementing the controls needed for effective AI management.

## Resources (Clause 7.1)

The AIMS cannot function without adequate resources. ISO 42001 requires organizations to determine and provide necessary resources.

### Types of Resources

**Human Resources**:

People are the most critical resource. The AIMS requires people with diverse skills:

**AI Technical Expertise**: Data scientists, machine learning engineers, and software developers who can build AI systems with appropriate technical controls.

**Domain Expertise**: Subject matter experts who understand the application domain, can identify appropriate use cases, and can evaluate whether AI systems are performing appropriately.

**Risk Management Expertise**: Professionals who understand risk assessment methodologies, can facilitate risk assessments, and can design risk management processes.

**Ethics and Responsible AI Expertise**: Professionals who understand ethical implications of AI, can facilitate ethical reviews, and can guide responsible AI practices.

**Legal and Compliance Expertise**: Lawyers and compliance professionals who understand applicable regulations, can assess compliance, and can provide legal guidance.

**Governance and Audit Expertise**: Professionals who can design governance structures, facilitate governance processes, and conduct audits.

**Communication and Stakeholder Engagement Expertise**: Professionals who can communicate about AI systems to diverse audiences and facilitate stakeholder engagement.

**Resource Planning Considerations**:
- Assess current expertise and identify gaps
- Determine whether to build expertise internally (hiring, training) or access externally (consultants, partnerships)
- Consider full-time dedicated roles vs. part-time shared roles
- Plan for ongoing resource needs, not just initial implementation

**Financial Resources**:

The AIMS requires budget for:
- Staff (salaries, contractors, consultants)
- Tools and technology (development tools, testing tools, monitoring systems, governance platforms)
- Training and professional development
- External assessments and audits
- Stakeholder engagement activities
- Documentation and communication systems

**Resource Planning Considerations**:
- Develop realistic budget based on scope and objectives
- Secure multi-year commitment (AIMS is ongoing, not one-time)
- Plan for both capital expenses (tools, infrastructure) and operating expenses (staff, training, audits)
- Establish process for adjusting budget based on evolving needs

**Technical Infrastructure**:

The AIMS requires infrastructure for:
- AI development (computing resources, development environments, data storage)
- AI testing and validation (test environments, test data, testing tools)
- AI deployment and operations (production infrastructure, deployment pipelines)
- AI monitoring (monitoring systems, logging, alerting)
- AI governance (documentation systems, workflow management, dashboards)

**Resource Planning Considerations**:
- Leverage existing infrastructure where possible
- Use cloud services for flexibility and scalability
- Ensure infrastructure meets security and privacy requirements
- Plan for infrastructure evolution as AI systems and AIMS mature

**Information and Knowledge**:

The AIMS requires access to:
- Technical documentation (system architecture, algorithms, data)
- Risk assessments and mitigation strategies
- Policies, standards, and procedures
- Training materials
- Regulatory guidance and industry best practices
- Incident reports and lessons learned

**Resource Planning Considerations**:
- Establish knowledge management systems
- Ensure information is accessible to those who need it
- Protect sensitive information appropriately
- Maintain information currency (update as systems and knowledge evolve)

### Resource Allocation

Resources must be allocated based on priorities:

**Risk-Based Allocation**: Allocate more resources to higher-risk AI systems. A high-risk medical diagnostic AI requires more extensive testing, monitoring, and oversight than a low-risk recommendation system.

**Lifecycle-Based Allocation**: Allocate resources across the AI lifecycle. Don't focus all resources on development while neglecting operations and monitoring.

**Capability-Building Allocation**: Invest in building organizational capabilities (training, tools, processes) that provide long-term benefits rather than only addressing immediate needs.

**Continuous vs. Project Allocation**: Balance resources for ongoing AIMS operation (monitoring, governance, continuous improvement) with resources for specific projects (new system development, capability building initiatives).

### Resource Monitoring

Monitor resource adequacy and utilization:
- Are resources sufficient to meet AIMS objectives?
- Are resources being used effectively?
- Are there resource bottlenecks or constraints?
- Do resource needs change as AI portfolio evolves?

Adjust resource allocation based on monitoring results and changing needs.

## Competence (Clause 7.2)

People doing work affecting the AIMS must be competent. ISO 42001 requires determining necessary competence, ensuring people have it, and retaining evidence.

### Competence Requirements

**AI Developers**:
- Technical skills in relevant AI techniques (machine learning, deep learning, NLP, computer vision, etc.)
- Understanding of AI risks and mitigation strategies
- Secure coding practices
- Testing and validation methodologies
- Documentation practices
- Relevant domain knowledge

**AI Operators**:
- Understanding of AI system capabilities and limitations
- Operational procedures and controls
- Monitoring and incident response
- Appropriate use and oversight
- Escalation procedures

**Risk Assessors**:
- Risk assessment methodologies
- AI-specific risks and assessment approaches
- Stakeholder engagement
- Documentation and reporting

**Governance Professionals**:
- Governance frameworks and processes
- Decision-making methodologies
- Stakeholder management
- Policy development

**Auditors**:
- Audit methodologies
- ISO 42001 requirements
- AI technical knowledge (sufficient to assess controls)
- Documentation review and evidence evaluation

### Building Competence

**Hiring**: Recruit people with necessary competence. Given AI talent scarcity, this may be challenging and expensive.

**Training**: Provide training to build competence:
- Technical training (AI techniques, tools, methodologies)
- Risk management training
- Ethics and responsible AI training
- Regulatory and compliance training
- Role-specific training

**Mentoring and Coaching**: Pair less experienced staff with experienced mentors.

**External Expertise**: Engage consultants or contractors to supplement internal competence.

**Communities of Practice**: Establish internal communities where people share knowledge and learn from each other.

**Continuous Learning**: Provide ongoing learning opportunities (conferences, courses, certifications) to maintain and enhance competence as AI field evolves.

### Evaluating Competence

Evaluate whether competence-building actions are effective:
- Assessments (tests, practical exercises)
- Performance reviews
- Peer reviews
- Audit findings (do audits reveal competence gaps?)
- Incident analysis (do incidents reveal competence gaps?)

### Documenting Competence

Retain documented information as evidence of competence:
- Education credentials
- Training records
- Certifications
- Work experience
- Performance evaluations
- Competence assessments

## Awareness (Clause 7.3)

People must be aware of the AI policy, their contribution to AIMS effectiveness, implications of non-conformity, and relevant AI impacts and risks.

### Awareness Content

**AI Policy**: Everyone should understand:
- What the AI policy says
- Why it matters
- How it affects their work
- Where to find it

**AIMS Contribution**: People should understand:
- How their role contributes to AIMS effectiveness
- What they're responsible for
- Why their actions matter
- How their work affects AI trustworthiness

**Non-Conformity Implications**: People should understand:
- What happens if AIMS requirements aren't followed
- Potential consequences (for individuals, organization, affected stakeholders)
- Why conformity matters

**AI Impacts and Risks**: People should understand:
- How AI systems can affect people and society
- What risks AI systems pose
- Why risk management is important
- Real examples of AI incidents and harms

### Building Awareness

**Onboarding**: Include AIMS awareness in onboarding for new employees.

**Training**: Provide awareness training to all relevant staff. Tailor content to roles (developers need different awareness than executives).

**Communications**: Regular communications about AIMS (newsletters, meetings, intranet posts).

**Campaigns**: Awareness campaigns around specific topics (AI ethics month, privacy awareness week).

**Leadership Messaging**: Leaders reinforce awareness through their communications and actions.

**Real Examples**: Share real examples of AI incidents, lessons learned, and successes to make awareness concrete.

**Reinforcement**: Reinforce awareness regularly (not just one-time training).

### Measuring Awareness

Assess whether awareness efforts are effective:
- Surveys measuring awareness levels
- Quiz or assessment results
- Observation of behaviors (do people follow AIMS requirements?)
- Incident analysis (do incidents reveal awareness gaps?)

Adjust awareness efforts based on measurement results.

## Communication (Clause 7.4)

Effective communication is essential for AIMS effectiveness. ISO 42001 requires determining what to communicate, when, with whom, and how.

### Internal Communication

**What to Communicate**:
- AI policy and objectives
- Roles and responsibilities
- Risk assessments and mitigation strategies
- Operational procedures and guidelines
- Monitoring results and performance metrics
- Incidents and lessons learned
- Changes to AIMS processes or requirements
- Successes and achievements

**Audiences**:
- Executives and board
- AI governance committee
- AI developers and operators
- Business units using AI
- All employees (for general awareness)

**Timing**:
- Regular communications (weekly, monthly, quarterly depending on content)
- Event-driven communications (incidents, major decisions, policy changes)
- On-demand communications (responding to questions, providing guidance)

**Methods**:
- Meetings (governance meetings, team meetings, town halls)
- Documentation (policies, procedures, guidelines)
- Digital channels (email, intranet, collaboration platforms)
- Training and workshops
- Dashboards and reports

### External Communication

**What to Communicate**:
- AI policy and principles
- Information about AI systems and their use
- How AI systems make decisions
- Rights and recourse mechanisms
- Performance and monitoring results (transparency reporting)
- Incidents and responses
- Regulatory reporting

**Audiences**:
- Customers and users
- Affected individuals
- Regulators
- Investors and shareholders
- Partners and suppliers
- Civil society organizations
- Media and general public

**Timing**:
- Proactive communications (transparency reports, policy announcements)
- Responsive communications (responding to inquiries, addressing concerns)
- Required communications (regulatory reporting, incident notifications)

**Methods**:
- Website (AI policy, transparency information, contact information)
- User interfaces (disclosures, explanations, consent mechanisms)
- Reports (transparency reports, regulatory filings)
- Direct communications (emails, letters, meetings)
- Public statements (press releases, social media)

### Communication Planning

Develop a communication plan that specifies:
- Communication objectives (what do we want to achieve?)
- Target audiences (who needs to receive each communication?)
- Messages (what do we want to communicate?)
- Channels (how will we communicate?)
- Timing (when will we communicate?)
- Responsibilities (who is responsible for each communication?)
- Feedback mechanisms (how will we know if communication is effective?)

### Communication Effectiveness

Evaluate communication effectiveness:
- Are target audiences receiving communications?
- Do they understand the messages?
- Are communications leading to desired outcomes (awareness, behavior change, trust)?
- What feedback are we receiving?
- How can we improve?

Adjust communication approach based on effectiveness evaluation.

## Documented Information (Clause 7.5)

Documentation provides evidence of AIMS implementation, enables knowledge sharing, supports accountability, and facilitates audits. ISO 42001 requires maintaining documented information.

### Required Documentation

**AIMS Scope**: Clear description of what's included in the AIMS.

**AI Policy**: The organization's AI policy.

**AI Objectives**: Established objectives and plans to achieve them.

**Risk Assessments**: Identified risks, assessments, and treatment plans.

**Competence Records**: Evidence of competence for people doing work affecting AIMS.

**Operational Procedures**: Procedures and controls for AI system development, deployment, and operation.

**Monitoring and Measurement Results**: Performance metrics, monitoring data, and analysis.

**Audit Reports**: Internal audit findings and recommendations.

**Management Review Records**: Management review inputs, discussions, and decisions.

**Incident Reports**: Documentation of incidents, investigations, and responses.

**Improvement Actions**: Nonconformities, corrective actions, and improvement initiatives.

**AI System Documentation**: For each AI system:
- System description and purpose
- Technical specifications (architecture, algorithms, data)
- Risk assessment
- Testing and validation results
- Deployment approval
- Operational procedures
- Monitoring results
- Change history

### Documentation Requirements

**Identification and Description**: Documents must be appropriately identified (title, date, version, author) and described.

**Format and Media**: Documents can be in any appropriate format (text, spreadsheet, diagram, video) and media (paper, electronic).

**Review and Approval**: Documents must be reviewed for adequacy and approved before use.

**Availability**: Documents must be available where and when needed. Implement document management systems that make documents accessible.

**Protection**: Documents must be protected:
- Confidentiality (access controls for sensitive information)
- Integrity (version control, change management)
- Availability (backups, redundancy)

**Control**: Documents must be controlled:
- Version control (track versions, identify current version)
- Change management (control changes, document rationale)
- Retention (retain for appropriate periods)
- Disposal (securely dispose when no longer needed)

### Documentation Best Practices

**Templates**: Develop templates for common document types (risk assessments, system documentation, incident reports) to ensure consistency and completeness.

**Document Management Systems**: Implement systems that support document creation, review, approval, version control, search, and access control.

**Balance**: Balance comprehensiveness with usability. Excessive documentation becomes burdensome and isn't used. Insufficient documentation creates gaps.

**Living Documents**: Treat documents as living artifacts that evolve, not static artifacts created once and forgotten.

**Integration**: Integrate documentation with workflows. Documentation should be natural part of work, not separate burden.

**Accessibility**: Make documents accessible to those who need them. Use clear language appropriate for audience.

## Operational Planning and Control (Clause 8.1)

Clause 8 addresses how AI systems are actually developed, deployed, and operated. Operational planning and control ensures processes are carried out in accordance with AIMS requirements.

### Establishing Process Criteria

For processes needed to meet AIMS requirements, establish criteria:

**AI System Development**:
- Requirements definition (functional, performance, trustworthiness)
- Design standards (architecture, algorithms, data)
- Implementation standards (coding practices, security measures)
- Testing requirements (performance, fairness, safety, security)
- Documentation requirements
- Approval gates (design review, deployment approval)

**AI System Deployment**:
- Deployment planning and preparation
- Infrastructure setup and configuration
- Monitoring system setup
- User training
- Gradual rollout procedures
- Deployment approval requirements

**AI System Operation**:
- Operational procedures and guidelines
- Monitoring and alerting
- Incident response procedures
- Change management procedures
- Periodic review and reassessment

### Implementing Process Controls

Controls ensure processes are carried out as planned:

**Technical Controls**:
- Automated checks (code quality, security vulnerabilities, bias detection)
- Testing frameworks and pipelines
- Monitoring and alerting systems
- Access controls and authentication

**Procedural Controls**:
- Standard operating procedures
- Checklists and templates
- Approval workflows
- Review and sign-off requirements

**Organizational Controls**:
- Roles and responsibilities
- Training and competence requirements
- Oversight and governance
- Escalation procedures

### Controlling Changes

Changes to AI systems or processes must be controlled:

**Planned Changes**:
- Assess impact of planned changes
- Plan implementation
- Test changes before deployment
- Document changes
- Communicate changes to affected parties

**Unintended Changes**:
- Detect unintended changes (monitoring, audits)
- Assess consequences
- Take corrective action if needed
- Understand root causes
- Prevent recurrence

### Outsourced Processes

When processes are outsourced (e.g., using third-party AI services, contracting development), ensure control:

**Vendor Assessment**: Assess vendors' capabilities and practices before engagement.

**Contractual Controls**: Establish requirements in contracts (performance, security, privacy, compliance).

**Ongoing Monitoring**: Monitor vendor performance and compliance.

**Audit Rights**: Maintain rights to audit vendors.

**Contingency Planning**: Plan for vendor failures or changes.

### Documentation of Operational Execution

Retain documented information demonstrating processes are carried out as planned:
- Test results
- Deployment records
- Monitoring logs
- Incident reports
- Change records
- Audit trails

## AI System Impact Assessment (Clause 8.2)

Before deploying AI systems, organizations must conduct impact assessments to identify and evaluate potential impacts on interested parties and society.

### Impact Assessment Purpose

Impact assessments ensure organizations understand:
- Who will be affected by the AI system
- How they will be affected (positive and negative impacts)
- What risks exist
- Whether risks are acceptable
- What mitigation measures are needed

### Impact Assessment Content

**System Description**:
- Purpose and intended use
- AI techniques and approaches
- Data sources and characteristics
- Deployment context
- User interface and interaction model

**Stakeholder Identification**:
- Who will directly use the system?
- Who will be affected by system decisions?
- Who else has interests in the system?

**Impact Analysis**:
- What are intended benefits?
- What are potential negative impacts (safety, privacy, fairness, autonomy, etc.)?
- Who experiences each impact?
- How severe are impacts?
- Are impacts reversible?
- Are certain groups disproportionately affected?

**Risk Assessment**:
- What is the likelihood of each negative impact?
- What is the overall risk level?
- How does risk compare to benefits?

**Mitigation Measures**:
- What controls and safeguards will be implemented?
- How effective are they?
- What residual risks remain?

**Decision**:
- Is deployment appropriate?
- What conditions or constraints apply?
- What monitoring is required?
- Who approves deployment?

### Impact Assessment Process

**1. Preparation**: Assemble assessment team with diverse perspectives (technical, domain, ethics, legal, affected stakeholders).

**2. System Characterization**: Document the system comprehensively.

**3. Stakeholder Engagement**: Engage with affected stakeholders to understand their perspectives and concerns.

**4. Impact Identification**: Systematically identify potential positive and negative impacts.

**5. Impact Evaluation**: Assess severity, likelihood, and distribution of impacts.

**6. Mitigation Planning**: Identify measures to prevent or reduce negative impacts.

**7. Residual Risk Assessment**: Evaluate remaining risks after mitigation.

**8. Decision-Making**: Determine whether deployment is appropriate and under what conditions.

**9. Documentation**: Document the assessment comprehensively.

**10. Communication**: Communicate findings to decision-makers and stakeholders.

### Impact Assessment Timing

**Pre-Deployment**: Comprehensive impact assessment before deploying new AI systems or significantly modifying existing ones.

**Periodic Reassessment**: Regular reassessment of production systems to identify emerging impacts.

**Triggered Reassessment**: Reassessment when circumstances change (incidents, performance changes, context changes, stakeholder concerns).

## Conclusion

Support and operations are where the AIMS becomes real. Support elements—resources, competence, awareness, communication, documentation—provide the foundation. Operational controls—process criteria, controls, change management, impact assessments—ensure AI systems are actually developed, deployed, and operated responsibly.

Without adequate support, even the best plans cannot be executed. Without effective operational controls, policies remain paper commitments rather than lived reality. Organizations that invest in building robust support capabilities and implementing rigorous operational controls find their AIMS effective in actually managing AI risks.

The next modules will explore how to evaluate whether support and operations are effective through monitoring, measurement, audits, and reviews, and how to continuously improve based on that evaluation.

## Key Takeaways

✅ ISO 42001 Clause 7 requires providing adequate resources (human, financial, technical, information) for AIMS effectiveness

✅ People doing work affecting AIMS must be competent, requiring assessment of competence needs, building competence through hiring/training, and documenting evidence

✅ Organizational awareness of AI policy, AIMS contribution, non-conformity implications, and AI risks must be built through training, communications, and reinforcement

✅ Effective communication requires planning what to communicate, when, with whom, and how for both internal and external audiences

✅ Comprehensive documentation must be maintained, appropriately identified, reviewed and approved, made available, protected, and controlled

✅ ISO 42001 Clause 8 requires operational planning and control with established process criteria, implemented controls, change management, and outsourced process control

✅ AI system impact assessments must be conducted before deployment to identify affected stakeholders, evaluate potential impacts, assess risks, plan mitigation, and make informed deployment decisions

✅ Impact assessments should involve diverse perspectives, engage stakeholders, systematically identify impacts, evaluate severity and likelihood, and document findings comprehensively

✅ Operational controls include technical controls (automated checks, monitoring), procedural controls (SOPs, approvals), and organizational controls (roles, training, oversight)

✅ Support and operations translate AIMS plans and policies into reality through adequate resources, competent people, effective processes, and rigorous controls
