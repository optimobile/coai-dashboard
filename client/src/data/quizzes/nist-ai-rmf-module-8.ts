import type { QuizQuestion } from '@/types/quiz';

export const nistAiRmfModule8Quiz: QuizQuestion[] = [
  {
    id: 1,
    question: 'What is the first step in implementing NIST AI RMF?',
    options: [
      'Deploy AI systems immediately',
      'Establish governance structures and secure leadership commitment',
      'Hire more developers',
      'Purchase AI tools',
    ],
    correctAnswer: 1,
    explanation: 'The first step is establishing governance structures, securing leadership commitment, and building organizational awareness. Without governance and leadership support, AI risk management efforts lack direction, resources, and accountability.',
  },
  {
    id: 2,
    question: 'Should NIST AI RMF implementation be tailored to organizational context?',
    options: [
      'No, use a one-size-fits-all approach',
      'Yes, tailor implementation to organizational size, risk appetite, resources, and AI use cases',
      'Only for large organizations',
      'Only if legally required',
    ],
    correctAnswer: 1,
    explanation: 'Yes, NIST AI RMF is designed to be flexible and should be tailored to organizational context, including size, risk appetite, resources, industry, and specific AI use cases. A startup and a hospital will implement differently.',
  },
  {
    id: 3,
    question: 'Should organizations start with high-risk AI systems or all AI systems?',
    options: [
      'Start with all systems simultaneously',
      'Prioritize high-risk systems, then expand to lower-risk systems',
      'Start with low-risk systems only',
      'Avoid high-risk systems entirely',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should prioritize high-risk AI systems where potential impacts are greatest, then expand to lower-risk systems. This risk-based approach ensures limited resources are focused where they matter most.',
  },
  {
    id: 4,
    question: 'What is the role of training in NIST AI RMF implementation?',
    options: [
      'Training is unnecessary',
      'Training builds AI risk management capabilities across the organization',
      'Training is only for developers',
      'Training is only for compliance teams',
    ],
    correctAnswer: 1,
    explanation: 'Training is essential for building AI risk management capabilities across the organization. Different roles need different training: leadership needs governance training, developers need technical training, and users need operational training.',
  },
  {
    id: 5,
    question: 'Should NIST AI RMF be integrated with existing risk management processes?',
    options: [
      'No, create completely separate processes',
      'Yes, integrate with existing enterprise risk management, compliance, and quality processes',
      'Only for large organizations',
      'Only if legally required',
    ],
    correctAnswer: 1,
    explanation: 'Yes, AI risk management should be integrated with existing enterprise risk management, compliance, quality assurance, and security processes. Integration avoids silos, leverages existing expertise, and ensures consistency.',
  },
  {
    id: 6,
    question: 'What is the purpose of pilot projects in NIST AI RMF implementation?',
    options: [
      'To delay full implementation',
      'To test approaches, learn lessons, and refine processes before scaling',
      'To avoid implementing the framework',
      'To satisfy auditors',
    ],
    correctAnswer: 1,
    explanation: 'Pilot projects test AI risk management approaches on a small scale, identify challenges, learn lessons, and refine processes before scaling across the organization. They provide practical experience and build confidence.',
  },
  {
    id: 7,
    question: 'Should NIST AI RMF implementation be a one-time project?',
    options: [
      'Yes, implement once and finish',
      'No, AI risk management is an ongoing process requiring continuous improvement',
      'Only update every 10 years',
      'Only update when regulations change',
    ],
    correctAnswer: 1,
    explanation: 'No, AI risk management is an ongoing process, not a one-time project. Organizations must continuously improve as AI systems evolve, new risks emerge, regulations change, and organizational context shifts.',
  },
  {
    id: 8,
    question: 'What metrics should organizations track during implementation?',
    options: [
      'Only financial metrics',
      'Process metrics (coverage, completion), outcome metrics (incidents, impacts), and maturity metrics',
      'Only compliance metrics',
      'No metrics needed',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should track process metrics (AI systems covered, assessments completed), outcome metrics (incidents prevented, impacts mitigated), and maturity metrics (governance maturity, capability development) to measure progress and effectiveness.',
  },
  {
    id: 9,
    question: 'Should organizations engage external stakeholders during implementation?',
    options: [
      'No, keep implementation internal',
      'Yes, engage affected stakeholders, civil society, and regulators to build trust and gather input',
      'Only if legally required',
      'Only after full implementation',
    ],
    correctAnswer: 1,
    explanation: 'Yes, organizations should engage external stakeholders including affected individuals, communities, civil society, and regulators. External engagement builds trust, identifies blind spots, and demonstrates commitment to responsible AI.',
  },
  {
    id: 10,
    question: 'What is the ultimate goal of NIST AI RMF implementation?',
    options: [
      'To pass audits',
      'To build trustworthy AI systems that benefit society while managing risks',
      'To avoid lawsuits',
      'To satisfy regulators',
    ],
    correctAnswer: 1,
    explanation: 'The ultimate goal is building trustworthy AI systems that benefit individuals, communities, and society while effectively managing risks. Compliance, audits, and regulation are means to this end, not the end itself.',
  },
];
