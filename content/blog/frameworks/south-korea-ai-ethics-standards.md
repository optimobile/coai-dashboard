_The Complete Guide to South Korea AI Ethics Standards: Everything You Need to Know for 2026 Compliance_

## Executive Summary

The South Korea AI Ethics Standards, formally known as the National Guidelines for Artificial Intelligence (AI) Ethics, represent a significant milestone in the global effort to establish a framework for responsible AI development and deployment. Released in December 2020, these guidelines were formulated to be a comprehensive set of standards for all members of society to follow in order to realize human-centered AI. The standards are built on the core value of "Humanity" and are articulated through three basic principles: respect for human dignity, the common good of society, and the proper use of technology. These principles are further broken down into ten key requirements that cover the entire AI system lifecycle, from data management to transparency and accountability.

For global AI governance, the South Korean standards are a crucial development. They signal a move towards a more harmonized global approach to AI ethics, drawing on internationally recognized human rights laws and democratic values. The standards are not just a domestic policy document; they have implications for any organization that provides AI-powered products or services to the South Korean market. With the passage of the Basic Act on Artificial Intelligence and Creation of a Trust Base in January 2025, which is set to take effect on January 22, 2026, these ethical guidelines are now backed by a legal framework that includes enforcement mechanisms and penalties for non-compliance. Organizations that need to comply include any business that develops, provides, or utilizes AI systems that impact the South Korean market, with a particular focus on high-impact AI systems in sectors like healthcare, finance, and employment.

## Historical Context

The development of South Korea's AI Ethics Standards is a story of a nation striving to balance rapid technological advancement with a commitment to humanistic values. The journey began long before the global AI boom, with the Ministry of Trade, Industry, and Energy releasing the 'Basic Principles of Robot Ethics' as early as 2007. This early initiative laid the groundwork for a more comprehensive approach to the ethical challenges posed by intelligent systems. As AI technology became more sophisticated and its societal impact more profound, the South Korean government recognized the need for a more robust and detailed framework.

The formalization of the AI Ethics Standards was driven by a multi-stakeholder process involving government bodies, academic institutions, and industry experts. The Ministry of Science and ICT (MSIT) and the Korea Information Society Development Institute (KISDI) were the key architects of the guidelines, working under the oversight of the Presidential Committee on the Fourth Industrial Revolution. This collaborative approach ensured that the resulting framework was not only technologically sound but also reflected a broad societal consensus on the ethical direction of AI.

The evolution of the framework has been marked by a shift from general principles to more concrete and actionable requirements. The initial guidelines, while comprehensive in their scope, were largely aspirational. However, with the passage of the Basic Act on Artificial Intelligence and Creation of a Trust Base in January 2025, these ethical principles have been codified into law. This legal backing, which will come into full force in January 2026, transforms the guidelines from a set of recommendations into a binding regulatory framework.

The political and economic drivers behind this evolution are clear. South Korea, as a global leader in technology and innovation, has a vested interest in fostering a thriving AI industry. However, the government also recognizes that public trust is a prerequisite for the successful adoption of AI. By establishing a clear ethical and legal framework, South Korea aims to create a safe and reliable environment for AI development, thereby boosting its national competitiveness while ensuring that the benefits of AI are shared by all members of society.

## Detailed Requirements Breakdown

The South Korean AI Ethics Standards, reinforced by the Basic Act on Artificial Intelligence, establish a comprehensive framework for AI governance. This framework is designed to be both promotional, encouraging innovation, and regulatory, building a foundation of trust. At its core is a risk-based approach that categorizes AI systems based on their potential impact on individuals and society. This section provides a detailed breakdown of the key requirements that organizations must adhere to.

### Risk Classification System

The South Korean framework introduces a risk classification system that, while not as explicitly tiered as the EU AI Act, distinguishes between general AI systems and “high-impact AI.” High-impact AI is defined as AI systems that can have a significant effect on the life, safety, and fundamental rights of individuals. This category includes, but is not limited to, AI used in critical sectors such as healthcare, employment, and finance. For example, AI systems used for medical diagnosis, recruitment and hiring, or credit scoring would likely be classified as high-impact. The law requires operators of high-impact AI to adhere to a stricter set of obligations, including conducting impact assessments and implementing robust safety and reliability measures.

### Prohibited AI Practices

While the South Korean framework does not provide an exhaustive list of prohibited AI practices in the same way as some other regulations, it does establish a clear principle that AI should not be used for purposes that are contrary to the public good or that infringe upon fundamental human rights. The National Guidelines for AI Ethics explicitly state that AI should not be developed or utilized in a way that violates human rights and freedom, or for the purpose of inflicting direct or indirect harm on humans. This principle-based prohibition provides a flexible yet firm boundary for AI development and application, allowing for adaptation as new technologies and use cases emerge.

### High-Risk AI Requirements

For AI systems classified as high-impact, the South Korean framework imposes a set of stringent requirements. These are designed to ensure that these powerful technologies are developed and deployed in a safe, reliable, and ethical manner. Key requirements for high-impact AI include:

*   **Impact Assessments:** Operators of high-impact AI systems are required to conduct thorough impact assessments to evaluate the potential effects of their systems on fundamental rights, privacy, and safety. These assessments must be documented and made available to regulatory authorities upon request.
*   **Risk Management:** Organizations must establish and maintain a comprehensive risk management system that covers the entire lifecycle of the AI system. This includes identifying, analyzing, and mitigating potential risks, as well as continuously monitoring the system for new and emerging risks.
*   **Safety and Reliability:** High-impact AI systems must be designed and built to be safe and reliable. This includes implementing measures to prevent errors, ensure robustness against attacks, and provide for a graceful degradation of performance in the event of a failure.

### Transparency Obligations

Transparency is a cornerstone of the South Korean AI ethics framework. The guidelines emphasize the importance of building social trust by providing clear and accessible information about how AI systems work. Key transparency obligations include:

*   **Notification of AI Use:** Businesses must notify users when they are interacting with a high-impact or generative AI system. This ensures that individuals are aware that they are not dealing with a human and can adjust their expectations accordingly.
*   **Labeling of AI-Generated Content:** Content that is generated by AI, such as text, images, or videos, must be clearly labeled as such. This is intended to prevent the spread of misinformation and to ensure that individuals can distinguish between human-created and machine-generated content.
*   **Explainability:** While recognizing the technical challenges, the framework encourages efforts to improve the explainability of AI systems. The goal is to provide users with a level of understanding of the AI’s decision-making process that is appropriate for the given use case.

### Data Governance Requirements

The South Korean framework places a strong emphasis on the responsible management of data throughout the AI lifecycle. The guidelines for data management are designed to protect privacy, prevent bias, and ensure the quality and integrity of the data used to train and operate AI systems. Key requirements include:

*   **Purpose Limitation:** Data collected for a specific purpose should not be used for other purposes without appropriate justification and, where necessary, consent.
*   **Data Quality and Bias:** Organizations must take steps to ensure the quality of the data they use and to minimize bias. This includes carefully managing the entire process of data collection, processing, and utilization.
*   **Privacy Protection:** The privacy of individuals must be protected at all stages of the AI lifecycle. This includes implementing appropriate technical and organizational measures to prevent the misuse and abuse of personal information.

### Human Oversight

The South Korean framework recognizes that technology alone is not enough to ensure ethical AI. Human oversight is a critical component of the governance framework, providing a necessary check on the power of automated systems. The law requires that organizations maintain a level of human oversight that is appropriate for the level of risk posed by the AI system. This can range from having a human in the loop for critical decisions to having a human on the loop for monitoring and intervention.

### Documentation and Record-Keeping

To ensure accountability and to facilitate regulatory oversight, the South Korean framework requires organizations to maintain detailed documentation about their AI systems. This includes documentation of the system’s design, development, and operation, as well as records of risk assessments, impact assessments, and any incidents that may occur. This documentation must be kept up-to-date and be made available to the relevant authorities upon request.

### Conformity Assessment Procedures

While the Basic Act on Artificial Intelligence lays the groundwork for conformity assessment, the specific procedures are still under development. It is expected that the Ministry of Science and ICT will release further decrees and guidelines that will detail the process for assessing whether AI systems, particularly high-impact systems, conform to the requirements of the law. This is likely to involve a combination of self-assessment, third-party audits, and regulatory inspections. Organizations should monitor these developments closely to ensure that they are prepared to meet the forthcoming conformity assessment requirements.

## Implementation Guide

Achieving compliance with the South Korea AI Ethics Standards and the accompanying Basic Act on Artificial Intelligence requires a structured and proactive approach. This guide provides a roadmap for organizations to navigate the implementation process, from initial assessment to ongoing monitoring. By following these steps, businesses can not only meet their legal obligations but also build a foundation of trust with their customers and stakeholders.

### Step-by-Step Compliance Roadmap

A successful compliance journey begins with a clear plan. Here is a step-by-step roadmap that organizations can follow:

1.  **Familiarization and Scoping:** The first step is to gain a thorough understanding of the South Korean AI framework. This involves a detailed review of the National Guidelines for AI Ethics and the Basic Act on Artificial Intelligence. Once the legal requirements are understood, the next step is to identify all AI systems within the organization that fall under the scope of the law, paying particular attention to those that may be classified as high-impact.

2.  **Gap Analysis:** With a clear understanding of the law and a comprehensive inventory of AI systems, organizations should conduct a gap analysis to identify any discrepancies between their current practices and the legal requirements. This analysis should cover all aspects of the AI lifecycle, from data governance and model development to deployment and monitoring.

3.  **Prioritization and Planning:** Based on the results of the gap analysis, organizations should prioritize the areas that require the most urgent attention. This will typically involve focusing on high-impact AI systems and addressing any significant compliance gaps. A detailed implementation plan should be developed, with clear timelines, responsibilities, and key performance indicators (KPIs).

4.  **Implementation and Integration:** This is the phase where the plan is put into action. It involves implementing the necessary technical and organizational measures to achieve compliance. This may include updating data governance policies, implementing new risk management processes, and enhancing transparency and explainability mechanisms. It is crucial that these measures are integrated into the organization's existing governance, risk, and compliance (GRC) framework.

5.  **Monitoring and Review:** Compliance is not a one-time project; it is an ongoing process. Organizations must continuously monitor their AI systems to ensure that they remain in compliance with the law. This includes regularly reviewing risk assessments, tracking performance metrics, and staying up-to-date with any changes in the regulatory landscape.

### Required Documentation

The South Korean framework places a strong emphasis on documentation. Organizations will be required to maintain a comprehensive set of records, including:

*   **AI System Inventory:** A complete list of all AI systems in use, including their purpose, scope, and risk classification.
*   **Impact Assessments:** Detailed reports of the impact assessments conducted for high-impact AI systems.
*   **Risk Management Framework:** Documentation of the organization's risk management framework, including risk assessments, mitigation measures, and monitoring procedures.
*   **Data Governance Policies:** Policies and procedures for data collection, processing, and management.
*   **Transparency and Explainability Records:** Documentation of the measures taken to ensure transparency and explainability, including user notifications and the labeling of AI-generated content.
*   **Training Records:** Records of the training provided to employees on AI ethics and compliance.

### Technical Requirements

From a technical perspective, organizations will need to implement a range of measures to comply with the South Korean framework. These may include:

*   **Data Lineage and Traceability:** Tools and processes to track the lineage of data used in AI systems, from its source to its use in a model.
*   **Model Versioning and Auditing:** Systems for versioning and auditing AI models to ensure that changes are tracked and can be reviewed.
*   **Bias Detection and Mitigation:** Tools and techniques for detecting and mitigating bias in AI models.
*   **Security and Robustness:** Measures to protect AI systems from attack and to ensure their robustness and reliability.
*   **Explainability and Interpretability:** Techniques for explaining the decisions made by AI systems in a way that is understandable to humans.

### Organizational Changes Needed

Compliance with the South Korean AI framework will require more than just technical changes; it will also necessitate organizational adjustments. These may include:

*   **Designation of a Responsible Person:** The law requires the designation of a person or a domestic representative responsible for AI compliance.
*   **Establishment of an AI Ethics Committee:** While not mandatory for all organizations, the formation of an autonomous AI ethics committee is strongly encouraged as a best practice.
*   **Cross-Functional Collaboration:** Compliance will require close collaboration between different teams, including legal, compliance, data science, and engineering.

### Training Requirements

To ensure that all employees are aware of their responsibilities under the new law, organizations will need to implement a comprehensive training program. This program should cover:

*   **The South Korean AI Ethics Standards and the Basic Act on Artificial Intelligence.**
*   **The organization's AI governance framework and policies.**
*   **The ethical implications of AI.**
*   **The roles and responsibilities of different employees in ensuring compliance.**

By investing in training, organizations can create a culture of responsible AI and empower their employees to make ethical decisions in their day-to-day work.

## Penalties and Enforcement

The South Korean government is serious about ensuring compliance with its new AI framework. The Basic Act on Artificial Intelligence introduces a range of penalties and enforcement mechanisms to hold organizations accountable for their AI systems. This section outlines the key provisions that businesses need to be aware of.

### Fines and Penalties for Non-Compliance

The most direct consequence of non-compliance is the imposition of financial penalties. The Act empowers the Ministry of Science and ICT to levy fines of up to KRW 30 million (approximately $20,870 USD) for violations. While this amount may seem modest compared to the fines imposed by some other data privacy regulations, it is important to note that this is just the starting point. The law also provides for the possibility of imprisonment for serious violations, signaling the gravity with which the South Korean government views AI-related risks.

### Enforcement Mechanisms

The primary enforcement body for the new AI law is the Ministry of Science and ICT. This ministry is tasked with developing the detailed implementation plans, decrees, and guidelines that will flesh out the specifics of the regulatory framework. The enforcement mechanisms are expected to include:

*   **Audits and Inspections:** The Ministry of Science and ICT will have the authority to conduct audits and inspections of organizations to assess their compliance with the law. This will likely involve a review of documentation, as well as technical testing of AI systems.
*   **Corrective Orders:** In cases of non-compliance, the ministry can issue corrective orders requiring organizations to take specific actions to bring their AI systems into compliance. Failure to comply with a corrective order can result in further penalties.
*   **Public Disclosure:** The government may also choose to publicly disclose the names of organizations that have violated the law. This can have a significant reputational impact, in addition to any financial penalties.

### Regulatory Bodies Involved

While the Ministry of Science and ICT is the lead regulatory body, it is expected to work closely with other government agencies to ensure a coordinated approach to AI governance. This may include collaboration with the Personal Information Protection Commission (PIPC) on issues related to data privacy, as well as with sector-specific regulators in areas such as finance and healthcare.

### Case Studies of Enforcement

As the law is not yet in full effect, there are no case studies of enforcement to date. However, organizations should monitor the regulatory landscape closely as the January 2026 enforcement date approaches. It is expected that the Ministry of Science and ICT will begin to take enforcement action soon after the law comes into force, and these early cases will provide valuable insights into how the law will be interpreted and applied in practice.

## How CSOAI Helps

Navigating the complex landscape of AI regulations can be a daunting task, but you don’t have to do it alone. The Council of Safe AI (CSOAI) is here to help. As a leading organization dedicated to promoting the safe and ethical development of AI, we offer a range of solutions and services designed to help your organization achieve compliance with the South Korea AI Ethics Standards and other global AI regulations.

### CEASAI Certification Alignment with South Korea AI Ethics Standards

At the heart of our offering is the CEASAI Certification, a globally recognized standard for AI safety and ethics. Our certification framework is closely aligned with the principles and requirements of the South Korea AI Ethics Standards, providing you with a clear and structured path to compliance. By achieving CEASAI certification, you can demonstrate to your customers, partners, and regulators that your AI systems are developed and deployed in a responsible and ethical manner.

### 33-Agent Byzantine Council for Compliance Verification

To ensure the integrity and impartiality of our certification process, we have established the 33-Agent Byzantine Council, a decentralized body of independent experts who are responsible for verifying compliance with the CEASAI standards. This innovative approach to governance, inspired by the principles of Byzantine fault tolerance, ensures that our certification decisions are robust, reliable, and free from bias.

### SOAI-PDCA Methodology for Continuous Compliance

Compliance is not a one-time event; it is an ongoing journey. That’s why we have developed the SOAI-PDCA (Plan-Do-Check-Act) methodology, a continuous improvement framework that helps you maintain compliance with the ever-evolving regulatory landscape. Our methodology provides you with the tools and processes you need to monitor your AI systems, identify and mitigate new risks, and continuously improve your AI governance practices.

### White-Label Solutions for Organizations

We understand that every organization is unique. That’s why we offer white-label solutions that can be customized to meet your specific needs. Whether you are a small startup or a large multinational corporation, we can provide you with a tailored solution that will help you achieve your AI governance goals.

### The £1 Billion Training Giveaway

To further our mission of promoting responsible AI, we are proud to announce the £1 billion training giveaway. This ambitious initiative will provide free training on AI ethics and safety to individuals and organizations around the world. By equipping people with the knowledge and skills they need to navigate the ethical challenges of AI, we can help to create a future where AI is a force for good.

## Comparison with Other Frameworks

The South Korea AI Ethics Standards are part of a growing global movement to establish clear and consistent rules for the development and deployment of artificial intelligence. While there is a broad consensus on the need for ethical AI, different jurisdictions have taken different approaches to regulation. This section compares the South Korean framework with other major AI governance frameworks, including the EU AI Act, the NIST AI Risk Management Framework, and the UK's pro-innovation approach.

### Interoperability and Global Harmonization

One of the key challenges facing organizations that operate in multiple jurisdictions is the need to navigate a complex and sometimes conflicting web of regulations. The South Korean framework, with its emphasis on internationally recognized principles of human rights and its risk-based approach, is well-positioned to be interoperable with other major AI governance frameworks. The focus on transparency, accountability, and safety aligns closely with the core principles of the EU AI Act and the NIST AI Risk Management Framework. As the global conversation on AI governance continues, there is a growing movement towards harmonization, and the South Korean framework is a significant contribution to this effort.

### Comparison Table

| Feature | South Korea AI Ethics Standards | EU AI Act | NIST AI Risk Management Framework | UK's Pro-Innovation Approach |
| :--- | :--- | :--- | :--- | :--- |
| **Legal Status** | Legally binding through the Basic Act on Artificial Intelligence | Legally binding regulation | Voluntary framework | Non-statutory, principles-based guidance |
| **Approach** | Risk-based, with a focus on high-impact AI | Risk-based, with a tiered system of obligations | Risk management framework to be integrated into existing processes | Sector-specific, with a focus on innovation and growth |
| **Key Focus** | Human-centered AI, ethics, and trust | Safety, fundamental rights, and a single market for AI | A practical and adaptable framework for managing AI risks | A flexible and pro-innovation regulatory environment |
| **Enforcement** | Ministry of Science and ICT, with fines and potential imprisonment | National supervisory authorities, with significant fines | No direct enforcement mechanism | Existing regulators, with a focus on guidance and collaboration |

While the South Korean framework shares many similarities with other major AI governance frameworks, there are also some key differences. The EU AI Act, for example, is more prescriptive in its approach, with a detailed list of prohibited AI practices and a more rigid risk classification system. The NIST AI Risk Management Framework, on the other hand, is a voluntary framework that is designed to be adaptable to different organizational contexts. The UK's approach is the most flexible, relying on existing regulators to apply a set of cross-sectoral principles in a way that is appropriate for their specific domains. The South Korean framework strikes a balance between these different approaches, providing a clear legal framework while also allowing for a degree of flexibility in its implementation.

## Future Outlook

The field of artificial intelligence is in a constant state of evolution, and the regulatory landscape is no exception. The South Korea AI Ethics Standards and the Basic Act on Artificial Intelligence provide a solid foundation for AI governance, but they are not the final word. As the technology continues to advance and its societal impact becomes more profound, we can expect to see further updates and amendments to the framework.

### Expected Updates and Amendments

One of the key areas where we can expect to see further development is in the specifics of the conformity assessment procedures. The Ministry of Science and ICT is expected to release more detailed guidance on how organizations can demonstrate compliance with the law. We may also see the development of sector-specific guidelines for high-risk areas such as healthcare and finance. As the global conversation on AI governance continues, we can also expect to see further efforts to harmonize the South Korean framework with other major international regulations.

### Emerging Requirements

As AI technology becomes more powerful and more integrated into our daily lives, we are likely to see the emergence of new regulatory requirements. These may include a greater focus on the environmental impact of AI, as well as new rules for the use of AI in areas such as autonomous vehicles and lethal autonomous weapons. The South Korean framework, with its principle-based approach, is well-positioned to adapt to these emerging challenges.

### Industry Trends

The trend towards greater AI regulation is clear, and it is not limited to South Korea. We are seeing a global movement towards a more responsible and ethical approach to AI, and this is likely to continue in the years to come. Organizations that embrace this trend and proactively adopt a strong AI governance framework will be well-positioned to succeed in the AI-powered economy of the future.

## Resources and Next Steps

This guide has provided a comprehensive overview of the South Korea AI Ethics Standards and the Basic Act on Artificial Intelligence. To help you on your compliance journey, we have compiled a list of resources and next steps.

### Official Documentation

*   **The National Guidelines for AI Ethics:** [https://ai.kisdi.re.kr/eng/main/contents.do?menuNo=500011](https://ai.kisdi.re.kr/eng/main/contents.do?menuNo=500011)
*   **Basic Act on Artificial Intelligence (unofficial translation):** [https://cset.georgetown.edu/wp-content/uploads/t0625_south_korea_ai_law_EN.pdf](https://cset.georgetown.edu/wp-content/uploads/t0625_south_korea_ai_law_EN.pdf)

### CSOAI Certification Programs

Ready to take the next step in your AI governance journey? Explore our CEASAI Certification programs and learn how you can achieve a globally recognized standard for AI safety and ethics.

### Contact for Enterprise Solutions

For large organizations and enterprises, we offer tailored solutions to meet your specific needs. Contact our enterprise solutions team today to learn more about how we can help you build a robust and responsible AI governance framework.


---

## Quick Reference

### Key Requirements Summary

1.  **Safeguarding Human Rights:** AI must be developed and used in a way that respects human rights and democratic values.
2.  **Protection of Privacy:** Personal privacy must be protected throughout the entire AI lifecycle.
3.  **Respect for Diversity:** AI systems should ensure diversity and representativeness, and minimize bias and discrimination.
4.  **Prevention of Harm:** AI should not be used to inflict direct or indirect harm on humans.
5.  **Public Good:** AI should be used for the public good and the common benefit of humanity.
6.  **Solidarity:** AI should be used to maintain solidarity among various groups and consider the needs of future generations.
7.  **Data Management:** Data must be used for its intended purpose, and data quality and risks must be managed.
8.  **Accountability:** Responsible parties must be clearly defined to minimize potential damage.
9.  **Safety:** Efforts must be made to prevent potential risks and ensure the safety of AI systems.
10. **Transparency:** The transparency and explainability of AI systems should be improved to build social trust.

### Implementation Timeline

*   **December 23, 2020:** The National Guidelines for Artificial Intelligence (AI) Ethics are adopted.
*   **January 21, 2025:** The Basic Act on Artificial Intelligence and Creation of a Trust Base is signed into law.
*   **January 22, 2026:** The Basic Act on Artificial Intelligence and Creation of a Trust Base takes effect.
*   **Ongoing:** The Ministry of Science and ICT will release further decrees and guidelines on the implementation of the law.

### How CSOAI Helps with South Korea AI Ethics Standards

*   **CEASAI Certification Alignment:** Achieve compliance with South Korea AI Ethics Standards through our globally recognized CEASAI Certification.
*   **33-Agent Byzantine Council:** Benefit from impartial and robust compliance verification by our independent council of experts.
*   **SOAI-PDCA Methodology:** Implement a continuous improvement framework to maintain compliance with the evolving regulatory landscape.
*   **White-Label Solutions:** Get a customized AI governance solution tailored to your organization's specific needs.
*   **£1 Billion Training Giveaway:** Access free training on AI ethics and safety to empower your team and build a culture of responsible AI.

### Framework Comparison

| Feature | South Korea AI Ethics Standards | EU AI Act | NIST AI Risk Management Framework | UK's Pro-Innovation Approach |
| :--- | :--- | :--- | :--- | :--- |
| **Legal Status** | Legally binding through the Basic Act on Artificial Intelligence | Legally binding regulation | Voluntary framework | Non-statutory, principles-based guidance |
| **Approach** | Risk-based, with a focus on high-impact AI | Risk-based, with a tiered system of obligations | Risk management framework to be integrated into existing processes | Sector-specific, with a focus on innovation and growth |
| **Key Focus** | Human-centered AI, ethics, and trust | Safety, fundamental rights, and a single market for AI | A practical and adaptable framework for managing AI risks | A flexible and pro-innovation regulatory environment |
| **Enforcement** | Ministry of Science and ICT, with fines and potential imprisonment | National supervisory authorities, with significant fines | No direct enforcement mechanism | Existing regulators, with a focus on guidance and collaboration |

---

*This guide is part of CSOAI's comprehensive AI governance resource library. For enterprise solutions, contact enterprise@csoai.org*
