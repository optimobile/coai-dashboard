_The Complete Guide to Singapore Model AI Governance Framework: Everything You Need to Know for 2026 Compliance_ is a comprehensive resource designed to help organizations understand and implement Singapore’s innovative approach to artificial intelligence (AI) governance. As AI technologies become increasingly integrated into business operations and daily life, the need for a robust governance framework is paramount. Singapore’s Model AI Governance Framework provides a principles-based, flexible, and globally-aligned approach to AI ethics and governance, enabling organizations to harness the transformative power of AI while mitigating its risks.

This guide provides a detailed breakdown of the framework, from its historical context to its practical implementation. It explores the key principles of explainability, transparency, fairness, and human-centricity that underpin the framework. It also delves into the operational requirements for organizations, including internal governance structures, risk management, and stakeholder communication. Furthermore, this guide offers a step-by-step roadmap for compliance, outlines the roles of regulatory bodies, and discusses the potential penalties for non-compliance.

With the rapid evolution of AI, particularly with the advent of generative AI, Singapore has demonstrated its commitment to staying at the forefront of AI governance by proposing updates to its framework. This guide covers these latest developments, including the nine dimensions of the proposed Model AI Governance Framework for Generative AI. It also provides a comparative analysis of Singapore’s framework with other major international frameworks, such as the EU AI Act and the NIST AI Risk Management Framework, highlighting the interoperability and global harmonization efforts.

For organizations seeking to implement the Singapore Model AI Governance Framework, this guide offers practical insights and actionable steps. It also highlights how the CSOAI (Council of Safe AI) platform can assist organizations in their compliance journey, from providing certification and training to offering white-label solutions. By following the guidance in this comprehensive resource, organizations can not only ensure compliance with the Singapore Model AI Governance Framework but also build trust with their stakeholders and unlock the full potential of AI in a responsible and ethical manner.

## Historical Context

Singapore's journey in AI governance began in 2018 with a series of strategic initiatives aimed at fostering a trusted AI ecosystem. The government recognized the transformative potential of AI and the importance of establishing a clear ethical and governance framework to guide its development and deployment. This led to the formation of the Advisory Council on the Ethical Use of AI and Data, which brought together experts from various fields to provide guidance on the responsible use of AI. The council's work culminated in the publication of a discussion paper that laid the groundwork for Singapore's AI governance framework.

In 2019, Singapore launched its first National AI Strategy (NAIS), a comprehensive plan to position the nation as a global leader in AI. The NAIS outlined a whole-of-government approach to driving AI innovation and adoption across the economy while ensuring that AI is developed and used responsibly. A key component of the NAIS was the development of the Model AI Governance Framework, which was first released in January 2019 at the World Economic Forum in Davos. The framework was designed to be a practical guide for organizations, providing them with a clear roadmap for implementing AI ethics and governance principles.

The political and economic drivers behind Singapore's AI governance framework are multifaceted. As a global business hub with a digitally-driven economy, Singapore recognized the need to create a pro-innovation environment that would attract AI talent and investment. At the same time, the government understood the importance of building public trust in AI to ensure its widespread adoption. The framework's flexible, principles-based approach was a deliberate choice to avoid stifling innovation with rigid regulations. Instead, it encourages voluntary compliance and shared responsibility between the government, industry, and the research community.

The evolution of the framework reflects Singapore's agile and adaptive approach to governance. The second edition of the Model AI Governance Framework was released in 2020, incorporating feedback from the industry and addressing new challenges. More recently, in response to the rapid advancements in generative AI, the AI Verify Foundation and IMDA have proposed a new Model AI Governance Framework for Generative AI. This demonstrates Singapore's commitment to keeping its governance framework relevant and effective in a constantly evolving technological landscape. The framework's emphasis on international cooperation and interoperability further underscores Singapore's ambition to play a leading role in shaping the global AI governance agenda.

## Detailed Requirements Breakdown

The Singapore Model AI Governance Framework is a comprehensive and principles-based framework that provides organizations with a clear roadmap for the responsible development and deployment of artificial intelligence (AI). Unlike more prescriptive regulatory frameworks, such as the EU AI Act, Singapore’s approach is designed to be flexible and adaptable, allowing organizations to tailor their governance practices to their specific context and risk profile. The framework is built on two core principles: ensuring that AI decision-making is explainable, transparent, and fair, and that AI systems are human-centric. These principles are supported by four key pillars that provide a practical foundation for AI governance: internal governance structures and measures, determining the level of human involvement in AI-augmented decision-making, operations management, and stakeholder interaction and communication.

### Risk-Based Approach

While the Singapore Model AI Governance Framework does not have a formal risk classification system with predefined categories of risk, it is fundamentally a risk-based framework. Organizations are encouraged to adopt a risk-based approach to AI governance, where the level of governance and oversight is commensurate with the potential risks and impact of the AI system. This means that organizations must conduct a thorough risk assessment to identify and evaluate the potential harms that their AI systems could cause to individuals, society, and the environment. The framework provides guidance on how to conduct these risk assessments, including considering factors such as the severity of potential harm, the likelihood of the harm occurring, and the extent to which the harm can be mitigated. Based on the results of the risk assessment, organizations can then implement appropriate governance measures to manage and mitigate the identified risks.

### Prohibited AI Practices

The Singapore Model AI Governance Framework does not contain a list of prohibited AI practices. This is in line with its principles-based and non-prescriptive approach. Instead of banning specific AI applications, the framework focuses on empowering organizations to make responsible decisions about the development and deployment of AI. The framework’s emphasis on ethical principles, risk management, and human oversight is intended to guide organizations away from developing and using AI in ways that could be harmful or malicious. The absence of a list of prohibited practices also allows the framework to remain relevant and adaptable in the face of rapid technological advancements. As new AI applications emerge, the framework’s principles can be applied to assess their potential risks and benefits, without the need for constant legislative updates.

### High-Risk AI Requirements

Although the Singapore Model AI Governance Framework does not have a formal category for “high-risk” AI systems, it provides clear guidance on the requirements for AI systems that have a significant impact on individuals. These are systems that can have a major influence on people’s lives, such as those used in hiring, credit scoring, and medical diagnosis. For these types of systems, the framework emphasizes the importance of the core principles of explainability, transparency, and fairness. Organizations must be able to explain how their AI systems make decisions, be transparent about their use of AI, and ensure that their AI systems are fair and do not discriminate against individuals or groups. The framework also stresses the need for a high degree of human oversight for these systems, to ensure that there is always a human in the loop who can intervene and override the AI’s decisions if necessary.

### Transparency Obligations

Transparency is a cornerstone of the Singapore Model AI Governance Framework. The framework requires organizations to be open and transparent about their use of AI, both internally and externally. This includes providing clear and accessible information to individuals about how their data is being used to train AI models and how AI is being used to make decisions that affect them. Organizations should also be transparent about the limitations of their AI systems and the potential risks involved. The framework encourages organizations to publish their AI governance policies and to provide channels for individuals to ask questions and provide feedback. By being transparent, organizations can build trust with their stakeholders and demonstrate their commitment to responsible AI.

### Data Governance Requirements

The Singapore Model AI Governance Framework recognizes that good data governance is a prerequisite for responsible AI. The framework emphasizes the importance of using high-quality data to train AI models and of taking steps to mitigate bias in data. Organizations should have clear policies and procedures in place for data management, including data collection, storage, and security. The framework also highlights the importance of data provenance, which is the ability to track the origin and history of data. This is crucial for ensuring the reliability and integrity of AI systems. By implementing robust data governance practices, organizations can improve the accuracy and fairness of their AI models and reduce the risk of making flawed decisions.

### Human Oversight Requirements

The principle of human-centricity is central to the Singapore Model AI Governance Framework. The framework stresses that AI should be used to augment human capabilities, not to replace them. It requires organizations to ensure that there is an appropriate level of human involvement in AI-augmented decision-making. This means that there should always be a human in the loop who can monitor the AI system, understand its reasoning, and intervene if necessary. The level of human oversight required will depend on the risk and impact of the AI system. For high-risk systems, a higher degree of human oversight will be necessary. By ensuring that there is always a human in the loop, organizations can mitigate the risks of AI and ensure that it is used in a way that is beneficial to humanity.

### Documentation and Record-Keeping

The Singapore Model AI Governance Framework requires organizations to maintain clear and comprehensive documentation of their AI systems. This includes documenting the design and development process, the data used to train the AI model, the results of testing and validation, and the decisions made by the AI system. Good documentation is essential for explainability, transparency, and accountability. It allows organizations to understand how their AI systems work, to identify and mitigate potential risks, and to demonstrate their compliance with the framework. The framework encourages organizations to use a variety of documentation methods, including data sheets for datasets, model cards for AI models, and audit trails for AI-driven decisions.

### Conformity Assessment Procedures

To help organizations assess their compliance with the Model AI Governance Framework, the Infocomm Media Development Authority (IMDA) has developed AI Verify, an AI governance testing framework and software toolkit. AI Verify provides a structured and standardized way for organizations to conduct technical tests on their AI models and to check their internal governance processes. The toolkit is based on 11 AI ethics principles that are aligned with international standards. By using AI Verify, organizations can generate testing reports that demonstrate the performance of their AI systems against these principles. These reports can be shared with stakeholders to build trust and confidence in their AI systems. AI Verify is a voluntary tool, but it provides a valuable resource for organizations that are committed to responsible AI.

## Implementation Guide

Implementing the Singapore Model AI Governance Framework requires a systematic and comprehensive approach. This guide provides a step-by-step roadmap to help organizations navigate the process and ensure compliance. The framework is designed to be flexible, so organizations should adapt this guide to their specific needs and context.

### Step-by-Step Compliance Roadmap

1.  **Establish a Cross-Functional AI Governance Committee:** The first step is to create a dedicated team responsible for overseeing the implementation of the AI governance framework. This committee should include representatives from various departments, such as legal, compliance, IT, data science, and business units. The committee's role is to define the organization's AI strategy, set policies and standards, and monitor compliance.

2.  **Conduct an AI Risk and Impact Assessment:** Before deploying any AI system, it is crucial to conduct a thorough assessment of its potential risks and impact. This assessment should identify potential harms to individuals, society, and the environment. The framework encourages a risk-based approach, so the level of governance should be proportionate to the identified risks.

3.  **Develop an AI Governance Policy:** Based on the risk assessment, the AI governance committee should develop a comprehensive AI governance policy. This policy should outline the organization's commitment to responsible AI and set clear guidelines for the development, deployment, and use of AI systems. The policy should address key areas such as data governance, transparency, human oversight, and accountability.

4.  **Implement Technical and Organizational Measures:** To put the AI governance policy into practice, organizations need to implement a range of technical and organizational measures. This includes using tools and techniques to ensure the fairness, transparency, and explainability of AI models. It also involves establishing clear roles and responsibilities for AI governance and providing training to employees.

5.  **Ensure Human Oversight:** The framework emphasizes the importance of human-centric AI. Organizations must ensure that there is an appropriate level of human involvement in AI-augmented decision-making. This may involve having a human in the loop to review and approve AI-driven decisions, especially in high-risk scenarios.

6.  **Maintain Comprehensive Documentation:** Organizations are required to maintain detailed documentation of their AI systems. This includes documenting the data used to train the models, the algorithms used, and the decisions made by the AI systems. This documentation is essential for transparency, accountability, and auditing purposes.

7.  **Establish a Process for Stakeholder Communication:** The framework encourages organizations to be transparent with their stakeholders about their use of AI. This includes providing clear and accessible information to customers, employees, and the public. Organizations should also establish channels for stakeholders to provide feedback and raise concerns.

8.  **Monitor and Review:** AI governance is an ongoing process. Organizations should continuously monitor the performance of their AI systems and review their governance framework to ensure that it remains effective and up-to-date. This includes conducting regular audits and assessments to identify and address any new risks or challenges.

### Required Documentation

*   **AI Governance Policy:** A formal document outlining the organization's approach to AI governance.
*   **Risk Assessment Reports:** Detailed reports of the risk assessments conducted for each AI system.
*   **Data Sheets for Datasets:** Documentation describing the datasets used to train AI models, including their source, characteristics, and any potential biases.
*   **Model Cards for AI Models:** Documentation providing information about the AI models, including their architecture, performance metrics, and limitations.
*   **Audit Trails:** Records of the decisions made by AI systems, including the data used and the reasoning behind the decisions.
*   **Training Materials:** Materials used to train employees on the organization's AI governance policies and procedures.

### Technical Requirements

*   **Fairness and Bias Mitigation Tools:** Tools and techniques to identify and mitigate bias in AI models.
*   **Explainability and Interpretability Tools:** Tools that help to explain how AI models make decisions.
*   **Robustness and Security Tools:** Tools to ensure that AI systems are secure and resilient to attacks.
*   **Data Governance Platforms:** Platforms to manage and govern the data used to train AI models.

### Organizational Changes Needed

*   **Creation of an AI Governance Committee:** A dedicated team to oversee AI governance.
*   **Appointment of an AI Ethics Officer:** An individual responsible for promoting ethical AI practices within the organization.
*   **Integration of AI Governance into Existing Risk Management Frameworks:** Incorporating AI-specific risks into the organization's overall risk management framework.
*   **Development of a Culture of Responsible AI:** Fostering a culture where employees are aware of the ethical implications of AI and are committed to responsible AI practices.

### Training Requirements

*   **AI Awareness Training for All Employees:** Basic training on AI and its ethical implications for all employees.
*   **AI Governance Training for the AI Governance Committee:** In-depth training on the organization's AI governance framework for the members of the AI governance committee.
*   **Technical Training for Data Scientists and Engineers:** Technical training on how to develop and deploy fair, transparent, and explainable AI models.

## Penalties and Enforcement

Unlike some other jurisdictions with specific AI-related penalties, Singapore's Model AI Governance Framework is a voluntary framework and does not have its own set of fines or penalties for non-compliance. Instead, enforcement is handled through existing legal and regulatory frameworks. This approach is consistent with Singapore's overall strategy of fostering a pro-innovation environment while ensuring that AI is used responsibly. Organizations that fail to adhere to the principles of the Model AI Governance Framework may face legal and financial consequences under various laws, depending on the nature of the violation.

### Enforcement Mechanisms

The primary enforcement mechanism for AI-related issues in Singapore is through sectoral regulators. For example, the Monetary Authority of Singapore (MAS) oversees the use of AI in the financial sector, while the Ministry of Health (MOH) regulates the use of AI in healthcare. These regulators have the authority to investigate and take action against organizations that violate their respective regulations. In addition to sectoral regulators, the Personal Data Protection Commission (PDPC) plays a key role in enforcing the Personal Data Protection Act (PDPA), which applies to the collection, use, and disclosure of personal data in Singapore. As AI systems often rely on large datasets of personal information, the PDPA is a critical piece of legislation for AI governance.

### Regulatory Bodies Involved

*   **Infocomm Media Development Authority (IMDA):** The IMDA is the lead agency for the development and promotion of the digital economy in Singapore. It is responsible for the development of the Model AI Governance Framework and the AI Verify toolkit.
*   **Personal Data Protection Commission (PDPC):** The PDPC is the main data protection authority in Singapore. It enforces the PDPA and provides guidance on data protection best practices.
*   **Sectoral Regulators:** Various sectoral regulators, such as the MAS and the MOH, are responsible for overseeing the use of AI in their respective industries.

### Case Studies of Enforcement

As the Model AI Governance Framework is a relatively new and voluntary framework, there are no publicly available case studies of enforcement actions specifically related to the framework. However, there have been cases where organizations have been penalized under the PDPA for data breaches that have involved AI systems. These cases highlight the importance of having robust data governance and security measures in place when using AI.

## How CSOAI Helps

The Council of Safe AI (CSOAI) is a leading organization dedicated to promoting the safe and ethical development and deployment of artificial intelligence. CSOAI offers a range of services and solutions to help organizations implement the Singapore Model AI Governance Framework and achieve their AI governance goals. With its deep expertise in AI safety and ethics, CSOAI is a trusted partner for organizations that are committed to responsible AI.

### CEASAI Certification Alignment with Singapore Model AI Governance Framework

CSOAI's Certified European AI Safety Analyst (CEASAI) certification is a globally recognized credential that demonstrates an individual's expertise in AI safety and governance. The CEASAI certification program is aligned with the principles and requirements of the Singapore Model AI Governance Framework. By obtaining the CEASAI certification, professionals can demonstrate their ability to implement the framework and to manage the risks associated with AI. The certification program covers key areas such as AI ethics, risk management, data governance, and transparency. It also provides in-depth training on the use of tools and techniques for developing and deploying fair, transparent, and explainable AI models.

### 33-Agent Byzantine Council for Compliance Verification

CSOAI has developed a unique and innovative approach to compliance verification called the 33-Agent Byzantine Council. This is a decentralized and distributed system of 33 AI agents that work together to assess an organization's compliance with the Singapore Model AI Governance Framework. The Byzantine Council uses a consensus-based approach to decision-making, which makes it highly resilient to errors and malicious attacks. By using the Byzantine Council, organizations can obtain an independent and objective assessment of their AI governance practices. This can help them to identify and address any gaps in their compliance and to build trust with their stakeholders.

### SOAI-PDCA Methodology for Continuous Compliance

CSOAI's SOAI-PDCA (Plan-Do-Check-Act) methodology is a continuous improvement framework that helps organizations to maintain their compliance with the Singapore Model AI Governance Framework over time. The SOAI-PDCA methodology is based on the well-established PDCA cycle, which is a four-step management method used for the control and continuous improvement of processes and products. The SOAI-PDCA methodology provides a structured approach to AI governance, helping organizations to plan their AI initiatives, implement their AI governance policies, check their compliance, and act on the results to improve their performance.

### White-label Solutions for Organizations

CSOAI offers white-label solutions that allow organizations to customize and brand CSOAI's AI governance tools and services as their own. This can be a cost-effective way for organizations to build their own AI governance capabilities without having to invest in developing their own tools and expertise. CSOAI's white-label solutions include a range of tools and services, such as AI risk assessment tools, data governance platforms, and AI ethics training programs. By using CSOAI's white-label solutions, organizations can accelerate their AI governance journey and demonstrate their commitment to responsible AI.

### The £1 Billion Training Giveaway

CSOAI is committed to building a global community of AI safety experts. To support this goal, CSOAI has launched a £1 billion training giveaway. This initiative provides free access to CSOAI's AI safety training programs for individuals and organizations around the world. The training programs cover a wide range of topics, from the basics of AI ethics to advanced techniques for developing and deploying safe and reliable AI systems. By participating in the training giveaway, individuals and organizations can gain the knowledge and skills they need to contribute to the safe and ethical development of AI.

## Comparison with Other Frameworks

Singapore's Model AI Governance Framework stands out for its principles-based, industry-led, and globally-oriented approach. Unlike more prescriptive regulations, it provides a flexible and adaptable framework that can be tailored to the specific needs of different organizations and industries. This section compares the Singaporean framework with other major AI governance frameworks around the world.

| Feature | Singapore Model AI Governance Framework | EU AI Act | NIST AI Risk Management Framework | UK's AI Framework |
| :--- | :--- | :--- | :--- | :--- |
| **Approach** | Principles-based, voluntary | Risk-based, legally binding | Voluntary, guidance-oriented | Pro-innovation, context-specific |
| **Risk Tiers** | No formal risk tiers, but risk-based approach | Four risk tiers: unacceptable, high, limited, minimal | No formal risk tiers, but focuses on risk management | No formal risk tiers, but focuses on sector-specific risks |
| **Enforcement** | Through existing laws and sectoral regulators | Through fines and penalties | No enforcement mechanism | Through existing regulators |
| **Focus** | Ethical principles, practical guidance | Compliance, safety, fundamental rights | Risk management, trustworthiness | Innovation, economic growth |

### EU AI Act

The EU AI Act is the most comprehensive and prescriptive AI regulation in the world. It takes a risk-based approach, categorizing AI systems into four tiers of risk: unacceptable, high, limited, and minimal. The Act imposes strict requirements on high-risk AI systems, including conformity assessments, data governance, and human oversight. In contrast, the Singaporean framework is voluntary and does not have a formal risk classification system. It provides guidance and best practices rather than legally binding requirements. While the EU AI Act focuses on compliance and enforcement, the Singaporean framework prioritizes innovation and industry-led governance.

### NIST AI Risk Management Framework

The NIST AI Risk Management Framework is a voluntary framework developed by the US National Institute of Standards and Technology. Like the Singaporean framework, it is designed to be flexible and adaptable to different contexts. The NIST framework provides a structured approach to managing the risks associated with AI, focusing on four key functions: govern, map, measure, and manage. The Singaporean framework is more principles-based, with a stronger emphasis on ethical considerations such as fairness and transparency. However, the two frameworks are highly compatible, and the IMDA and NIST have published a crosswalk to show how they can be used together.

### UK's AI Framework

The UK's AI framework is a pro-innovation and context-specific framework that aims to strike a balance between supporting innovation and addressing the risks of AI. Like the Singaporean framework, it is not a one-size-fits-all regulation. Instead, it relies on existing regulators to develop their own approaches to AI governance within their respective sectors. The UK framework is based on five principles: safety, security, and robustness; transparency and explainability; fairness; accountability and governance; and contestability and redress. These principles are closely aligned with the principles of the Singaporean framework, and both frameworks share a common goal of promoting responsible AI innovation.

## Future Outlook

Singapore's AI governance landscape is expected to continue evolving in the coming years, driven by rapid technological advancements and a growing global consensus on the need for responsible AI. The proposed Model AI Governance Framework for Generative AI is a clear indication of Singapore's commitment to staying at the forefront of AI governance. We can expect to see further updates and refinements to the framework as new challenges and opportunities emerge. The focus will likely remain on a principles-based, industry-led, and globally-aligned approach that fosters innovation while mitigating risks.

One of the key trends that will shape the future of AI governance in Singapore is the increasing importance of international cooperation. As AI systems become more interconnected and cross-border data flows become more common, the need for a harmonized global approach to AI governance will grow. Singapore is well-positioned to play a leading role in this process, thanks to its strong international partnerships and its commitment to interoperability. We can expect to see Singapore continue to actively participate in global dialogues on AI governance and to contribute to the development of international standards and best practices.

Another important trend is the growing demand for AI transparency and explainability. As AI systems become more complex and autonomous, it will become increasingly important for organizations to be able to explain how their AI systems make decisions. This will require the development of new tools and techniques for AI explainability, as well as a shift in organizational culture towards greater transparency. The Singaporean framework's emphasis on explainability and transparency will likely become even more critical in the future.

## Resources and Next Steps

For organizations looking to implement the Singapore Model AI Governance Framework, there are a number of resources available to help you on your journey. The official documentation for the framework can be found on the website of the Infocomm Media Development Authority (IMDA). The IMDA also provides a range of other resources, including the AI Verify toolkit and a series of guides and primers on AI governance.

CSOAI also offers a range of resources and services to help organizations with their AI governance needs. Our CEASAI certification program provides in-depth training on the Singapore Model AI Governance Framework, and our 33-Agent Byzantine Council can help you to assess your compliance with the framework. We also offer white-label solutions and a £1 billion training giveaway to support the global AI safety community.

For enterprise solutions and to learn more about how CSOAI can help your organization, please contact us. Our team of experts is ready to assist you in your journey towards responsible AI.

---

## Quick Reference

### Key Requirements Summary

1.  Establish a cross-functional AI Governance Committee.
2.  Conduct AI Risk and Impact Assessments for all AI systems.
3.  Develop and maintain a comprehensive AI Governance Policy.
4.  Implement technical and organizational measures for fairness, transparency, and explainability.
5.  Ensure appropriate human oversight for AI-augmented decision-making.
6.  Maintain comprehensive documentation of AI systems, including data sheets and model cards.
7.  Establish a process for stakeholder communication and feedback.
8.  Continuously monitor and review the AI governance framework.
9.  Use high-quality data and mitigate bias in AI models.
10. Ensure the security and robustness of AI systems.

### Implementation Timeline

*   **Q1 2026:** Establish AI Governance Committee and develop AI Governance Policy.
*   **Q2 2026:** Conduct AI Risk and Impact Assessments for existing AI systems.
*   **Q3 2026:** Implement technical and organizational measures for AI governance.
*   **Q4 2026:** Conduct first internal audit of AI governance framework and begin continuous monitoring.
*   **Ongoing:** Annual review of AI governance framework and training for employees.

### How CSOAI Helps with Singapore Model AI Governance Framework

*   CEASAI Certification aligns with the Singapore Model AI Governance Framework, providing certified professionals to guide implementation.
*   The 33-Agent Byzantine Council offers independent and robust compliance verification.
*   The SOAI-PDCA methodology provides a framework for continuous compliance and improvement.
*   White-label solutions enable organizations to quickly deploy AI governance tools.
*   The £1 billion training giveaway provides free access to AI safety training.

### Framework Comparison

| Feature | Singapore Model AI Governance Framework | EU AI Act | NIST AI Risk Management Framework | UK's AI Framework |
| :--- | :--- | :--- | :--- | :--- |
| **Approach** | Principles-based, voluntary | Risk-based, legally binding | Voluntary, guidance-oriented | Pro-innovation, context-specific |
| **Risk Tiers** | No formal risk tiers, but risk-based approach | Four risk tiers: unacceptable, high, limited, minimal | No formal risk tiers, but focuses on risk management | No formal risk tiers, but focuses on sector-specific risks |
| **Enforcement** | Through existing laws and sectoral regulators | Through fines and penalties | No enforcement mechanism | Through existing regulators |
| **Focus** | Ethical principles, practical guidance | Compliance, safety, fundamental rights | Risk management, trustworthiness | Innovation, economic growth |

---

*This guide is part of CSOAI's comprehensive AI governance resource library. For enterprise solutions, contact enterprise@csoai.org*
