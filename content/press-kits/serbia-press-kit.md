# Press Kit: AI Safety Framework for Serbia

## Press Release Template

**FOR IMMEDIATE RELEASE**

**[City, State, Date]** – The Council of Safe AI (CSOAI) today announced a strategic initiative to support the Republic of Serbia in developing a national AI safety framework. This initiative comes as the European Union’s AI Act deadline of February 2, 2026, approaches, creating an urgent need for non-EU countries like Serbia to align with new global standards for artificial intelligence.

CSOAI will offer Serbia its white-label AI Safety Framework, a comprehensive and customizable governance solution designed to ensure the safe and ethical use of AI technologies. The framework is fully compliant with the EU AI Act and can be adapted to Serbia’s specific legal and cultural context.

“Serbia has already demonstrated its commitment to becoming a regional leader in the digital economy,” said [CSOAI Spokesperson Name], [Title] at CSOAI. “We are excited to partner with Serbia to build a robust AI governance framework that will not only mitigate the risks associated with AI but also foster innovation and economic growth.”

In addition to the AI Safety Framework, CSOAI will provide its CEASAI Certification program to train and certify 1,000 AI Safety Analysts in Serbia. This program is part of a £1 billion global training giveaway, which aims to create a worldwide community of experts in AI safety and governance.

“By providing free access to our world-class training, we are empowering Serbian citizens with the skills they need to thrive in the AI-powered economy of the future,” said [CSOAI Spokesperson Name]. “This will create immediate capacity for AI governance in Serbia and ensure that the country has the human capital needed to lead the way in responsible AI.”

CSOAI’s initiative will be implemented in four phases, starting with a comprehensive assessment of Serbia’s existing AI landscape. This will be followed by the deployment of the AI Safety Framework, the training of AI Safety Analysts, and the establishment of full operational capability.

**About CSOAI:**

The Council of Safe AI (CSOAI) is a global organization dedicated to promoting the safe and ethical development of artificial intelligence. We provide governments, businesses, and civil society organizations with the tools and expertise they need to navigate the complexities of AI governance.

**Contact:**

[Name]

[Title]

[Email]

[Phone Number]

---

## Key Media Contacts

### Major News Outlets in Serbia
Blic, Kurir, Mondo, Večernje Novosti, Danas, RTS (Radio Television of Serbia), N1, Balkan Insight

### Key Journalists to Contact
Katarina Baletic - Balkan Insight - Serbia Correspondent, Misha Savic - Bloomberg - Journalist, Ivana Milosavljević - CINS - Reporter

---

## Key Messages

### AI Challenges in Serbia
- Limited AI adoption outside of the ICT and professional services sectors.
- Shortage of skilled AI professionals, particularly in machine learning and data analytics.
- Need for a comprehensive legal and ethical framework for AI to build trust and encourage investment.

### Recommended Partnership Tier
National Authority (£1M+)

---

## About CSOAI

The Council of Safe AI (CSOAI) is a UK-based company dedicated to making AI safety accessible globally. Our mission is to train 500,250 AI Safety Analysts worldwide through our £1 billion training giveaway program.

### Key Statistics
- 118 countries currently lack AI governance frameworks
- EU AI Act enforcement deadline: February 2, 2026
- 250,000+ AI Safety Analyst jobs needed globally
- CEASAI Certification: £499-£1,999 (FREE through giveaway)

### Contact Information
- Website: https://csoai.org
- Press Inquiries: press@csoai.org
- Government Partnerships: government@csoai.org
- Phone: +44 (0) 20 XXXX XXXX

### Downloadable Assets
- CSOAI Logo (Light): https://csoai.org/assets/logo-light.svg
- CSOAI Logo (Dark): https://csoai.org/assets/logo-dark.svg
- CEASAI Badge: https://csoai.org/assets/ceasai-badge.svg
- Press Photos: https://csoai.org/press/photos

---

*This press kit was generated for Serbia as part of CSOAI's Global AI Safety Initiative.*
