# Module 8: Compliance Timeline, Penalties, and Next Steps

**Duration**: 60 minutes  
**Learning Objectives**:
- Understand the phased implementation timeline
- Recognize penalty structures and enforcement mechanisms
- Identify immediate compliance actions
- Plan your organization's compliance roadmap

---

## Introduction

The EU AI Act entered into force on **August 1, 2024**. However, most provisions apply on a **phased timeline** over 24-36 months. Understanding this timeline is critical for prioritizing compliance efforts.

This final module covers:
1. Phased implementation timeline
2. Penalty structures and enforcement
3. Immediate compliance actions
4. Long-term compliance roadmap
5. Resources and next steps

## Phased Implementation Timeline

The Act uses a staggered approach, with the most serious risks addressed first and more complex requirements phased in gradually.

### Phase 1: Prohibited Practices (6 Months)
**Deadline: February 2, 2025**

**What becomes enforceable**:
- All prohibited AI practices (Article 5)
  * Subliminal manipulation
  * Exploitation of vulnerabilities
  * Social scoring by public authorities
  * Biometric categorization of sensitive attributes
  * Predictive policing based solely on profiling
  * Untargeted scraping of facial images
  * Emotion recognition in workplaces and schools
  * Real-time biometric identification in public spaces (with narrow exceptions)

**Why this comes first**: These practices are deemed unacceptable risks that must be eliminated immediately.

**Action required**: Organizations must **cease all prohibited practices** by February 2, 2025. No transition period, no grandfathering, no compliance pathway—just cessation.

**Enforcement**: Penalties apply from February 2, 2025 for any prohibited practice deployment.

### Phase 2: GPAI Codes of Practice (12 Months)
**Deadline: August 2, 2025**

**What becomes enforceable**:
- GPAI providers must follow codes of practice or explain deviations (Articles 56)
- Codes of practice development process begins

**Why this comes second**: GPAI regulation is new and complex, requiring industry collaboration to develop practical compliance standards.

**Action required**: GPAI providers should participate in codes of practice development and prepare to implement agreed-upon standards.

### Phase 3: General Governance and Transparency (12 Months)
**Deadline: August 2, 2025**

**What becomes enforceable**:
- Transparency obligations for all AI systems (Article 50)
  * AI interaction disclosure (chatbots, virtual assistants)
  * Emotion recognition and biometric categorization disclosure
  * Deep fake disclosure
- Governance structure establishment
  * AI Office operational
  * European AI Board established
  * National competent authorities designated

**Why this timing**: Transparency requirements are relatively straightforward to implement and apply broadly.

**Action required**: All AI system providers must implement disclosure mechanisms by August 2, 2025.

### Phase 4: High-Risk AI Systems (24 Months)
**Deadline: August 2, 2026**

**What becomes enforceable**:
- All requirements for high-risk AI systems (Chapters II and III, Section 2)
  * Risk management systems
  * Data governance
  * Technical documentation
  * Record-keeping and logging
  * Transparency to deployers
  * Human oversight
  * Accuracy, robustness, cybersecurity
  * Quality management systems
  * Conformity assessment
  * Registration
  * Post-market monitoring
  * Incident reporting

**Why this timing**: High-risk compliance is complex, requiring significant organizational changes, system redesigns, and documentation.

**Action required**: Providers of high-risk AI systems must achieve full compliance by August 2, 2026. This is the most significant deadline for most organizations.

### Phase 5: GPAI Obligations (24 Months)
**Deadline: August 2, 2026**

**What becomes enforceable**:
- All GPAI provider obligations (Articles 53, 55)
  * Technical documentation
  * Information to downstream providers
  * Copyright compliance
  * Public training data summary
  * Model evaluation (systemic risk models)
  * Risk assessment and mitigation (systemic risk models)
  * Incident tracking and reporting (systemic risk models)
  * Cybersecurity protection (systemic risk models)

**Why this timing**: Aligns with high-risk system requirements, as many high-risk systems use GPAI models.

**Action required**: GPAI providers must achieve full compliance by August 2, 2026.

### Phase 6: Existing High-Risk AI Systems (36 Months)
**Deadline: August 2, 2027**

**What becomes enforceable**:
- High-risk AI systems already on the market before August 2, 2026 must comply

**Why this timing**: Provides additional time for legacy systems to be brought into compliance or phased out.

**Action required**: Organizations with existing high-risk AI systems have until August 2, 2027 to achieve compliance or discontinue use.

**Important**: This extended deadline applies only to systems **already on the market** before August 2, 2026. New high-risk systems placed on the market after August 2, 2026 must be compliant immediately.

## Timeline Summary Table

| Deadline | Phase | What's Enforceable | Who's Affected |
|----------|-------|-------------------|----------------|
| **Feb 2, 2025** | Prohibited Practices | Article 5 prohibitions | All organizations deploying prohibited AI |
| **Aug 2, 2025** | GPAI Codes + Transparency | Articles 50, 56 | All AI providers (transparency), GPAI providers (codes) |
| **Aug 2, 2026** | High-Risk + GPAI | Chapters II-III, Articles 53, 55 | High-risk AI providers/deployers, GPAI providers |
| **Aug 2, 2027** | Legacy High-Risk | Chapter III (existing systems) | Organizations with pre-2026 high-risk AI |

## Penalty Structure (Article 99)

The EU AI Act establishes severe penalties for non-compliance, structured in tiers based on violation severity.

### Tier 1: Maximum Penalties (Prohibited Practices)
**€35 million OR 7% of total worldwide annual turnover** (whichever is higher)

**Violations**:
- Deploying prohibited AI practices (Article 5)
- Non-compliance with GPAI obligations (Articles 53, 55)

**Why these are highest**: Prohibited practices and powerful GPAI models pose the greatest risks.

**Real-world impact**: For a company with €10 billion annual revenue, the penalty could reach €700 million. For smaller companies, €35 million is still devastating.

### Tier 2: High Penalties (High-Risk Non-Compliance)
**€15 million OR 3% of total worldwide annual turnover** (whichever is higher)

**Violations**:
- Non-compliance with high-risk AI system obligations (Chapter III, Section 2)
- Non-compliance with deployer obligations (Article 26)
- Non-compliance with notified body requirements (Article 33)

**Why these are high**: High-risk systems significantly impact fundamental rights and safety.

**Real-world impact**: For a company with €10 billion annual revenue, the penalty could reach €300 million.

### Tier 3: Moderate Penalties (Information Obligations)
**€7.5 million OR 1.5% of total worldwide annual turnover** (whichever is higher)

**Violations**:
- Supplying incorrect, incomplete, or misleading information to authorities
- Failing to respond to authority requests
- Non-compliance with transparency obligations (Article 50)

**Why these are moderate**: While serious, these violations are less directly harmful than deploying non-compliant systems.

**Real-world impact**: For a company with €10 billion annual revenue, the penalty could reach €150 million.

### SME Adjustments

**Definition**: Small and medium-sized enterprises (SMEs) and startups as defined under EU law.

**Adjustment**: Penalties are **proportionally adjusted** for SMEs, taking into account:
- Company size
- Market position
- Financial situation
- Violation severity

**Purpose**: Ensure penalties are effective deterrents without destroying small businesses.

**Real-world impact**: A startup with €5 million annual revenue facing a Tier 1 violation would not pay €35 million (which would bankrupt them) but a proportionally adjusted amount considering their size.

### Penalty Considerations

Authorities consider several factors when determining penalties:

**Aggravating factors** (increase penalties):
- Intentional or negligent violation
- Previous violations
- Refusal to cooperate with authorities
- Harm caused or potential harm
- Profits gained from violation

**Mitigating factors** (decrease penalties):
- Voluntary disclosure of violation
- Cooperation with authorities
- Prompt corrective action
- Demonstrated good faith efforts to comply

**Real-world scenario**: A company that discovers a compliance issue, immediately reports it to authorities, takes corrective action, and cooperates fully with investigation will face significantly lower penalties than a company that conceals violations and resists enforcement.

## Enforcement Mechanisms

### Market Surveillance

**National authorities** conduct market surveillance activities:
- Monitoring AI systems on the market
- Investigating complaints
- Conducting inspections and audits
- Requesting information and documentation
- Testing AI systems

**AI Office** supervises GPAI providers:
- Monitoring frontier AI models
- Investigating systemic risk models
- Coordinating with national authorities

### Corrective Measures

Before imposing penalties, authorities typically issue **corrective measures**:

**Non-compliance notice**: Inform provider/deployer of violation and require corrective action within specified timeframe.

**Market restriction**: Prohibit placing AI system on market or require withdrawal until compliance is achieved.

**Product recall**: Require recall of non-compliant AI systems already deployed.

**Use prohibition**: Prohibit deployers from using non-compliant AI systems.

**Real-world scenario**: If a national authority discovers a high-risk hiring AI system lacks required documentation, they will likely first issue a non-compliance notice requiring the provider to create documentation within 30-60 days. Only if the provider fails to comply will penalties be imposed.

### Complaints and Whistleblowing

**Right to complain**: Any person or organization can file complaints with national authorities about suspected violations.

**Whistleblower protection**: Individuals reporting violations are protected from retaliation under EU whistleblower protection laws.

**Real-world impact**: Employees, customers, or civil society organizations can trigger investigations by reporting suspected non-compliance.

## Immediate Compliance Actions

Regardless of your organization's size or AI maturity, certain actions should be taken immediately.

### Action 1: Inventory All AI Systems

**What**: Create a comprehensive list of all AI systems your organization:
- Develops (provider role)
- Uses (deployer role)
- Plans to develop or deploy

**How**:
1. Survey all departments and teams
2. Identify AI tools, platforms, and systems
3. Document each system's purpose, capabilities, and users
4. Classify systems by risk level

**Why**: You cannot comply with what you don't know exists. Many organizations are surprised by how many AI systems they use.

**Timeline**: Complete within 30 days.

### Action 2: Assess Prohibited Practices

**What**: Evaluate whether any AI systems involve prohibited practices.

**How**:
1. Review Article 5 prohibited practices (Module 3)
2. For each AI system, explicitly assess whether it falls into prohibited categories
3. Document your assessment
4. If any prohibited practices are identified, plan immediate cessation

**Why**: Prohibited practices must be eliminated by February 2, 2025—the first enforcement deadline.

**Timeline**: Complete within 60 days. Cease prohibited practices immediately upon identification.

### Action 3: Classify High-Risk Systems

**What**: Determine which AI systems are high-risk under Annex I or Annex III.

**How**:
1. Review Annex I (safety components) and Annex III (use cases) (Modules 4-5)
2. For each AI system, assess whether it falls into high-risk categories
3. Consider exceptions (narrow procedural tasks, etc.)
4. Document your classification and reasoning
5. Prioritize high-risk systems for compliance efforts

**Why**: High-risk systems face extensive compliance obligations by August 2, 2026.

**Timeline**: Complete within 90 days.

### Action 4: Identify Transparency Obligations

**What**: Determine which AI systems require transparency disclosures.

**How**:
1. Identify systems that interact with people (chatbots, virtual assistants)
2. Identify emotion recognition or biometric categorization systems
3. Identify systems that generate or manipulate media (deepfakes)
4. Plan disclosure mechanisms for each

**Why**: Transparency obligations apply to all AI systems by August 2, 2025.

**Timeline**: Complete within 90 days. Implement disclosures by August 2, 2025.

### Action 5: Assign Responsibility

**What**: Designate individuals or teams responsible for AI Act compliance.

**How**:
1. Identify executive sponsor (C-level or senior leadership)
2. Assign compliance lead (legal, compliance, or product team)
3. Establish cross-functional working group (legal, technical, product, risk)
4. Define roles and responsibilities
5. Allocate budget and resources

**Why**: Compliance requires sustained, coordinated effort across the organization.

**Timeline**: Complete within 30 days.

### Action 6: Educate Stakeholders

**What**: Ensure key personnel understand the EU AI Act and its implications.

**How**:
1. Provide training for executives, product managers, engineers, legal, and compliance teams
2. Share this course or similar educational resources
3. Conduct workshops on specific topics (prohibited practices, high-risk classification, etc.)
4. Create internal guidance documents

**Why**: Compliance requires organization-wide awareness and understanding.

**Timeline**: Begin immediately. Ongoing education.

## Long-Term Compliance Roadmap

### For Providers of High-Risk AI Systems

**Phase 1: Assessment and Planning (Months 1-3)**
- Complete AI system inventory
- Classify high-risk systems
- Conduct gap analysis against requirements
- Develop compliance roadmap and budget
- Assign responsibilities

**Phase 2: Foundation Building (Months 4-9)**
- Establish risk management system
- Implement data governance practices
- Develop quality management system
- Create technical documentation templates
- Design logging and record-keeping systems

**Phase 3: System-Specific Compliance (Months 10-18)**
- For each high-risk system:
  * Conduct comprehensive risk assessment
  * Implement risk mitigation measures
  * Create technical documentation
  * Design human oversight mechanisms
  * Conduct accuracy, robustness, cybersecurity testing
  * Prepare instructions for use

**Phase 4: Conformity Assessment (Months 19-21)**
- Conduct internal conformity assessment (or engage notified body)
- Address any identified gaps
- Draw up EU declaration of conformity
- Affix CE marking

**Phase 5: Market Entry Preparation (Months 22-24)**
- Register systems in EU database
- Finalize instructions for use
- Establish post-market monitoring system
- Train deployer support teams
- Prepare for market launch

**Phase 6: Ongoing Compliance (Month 24+)**
- Monitor system performance
- Respond to incidents
- Update documentation and risk assessments
- Maintain quality management system
- Engage with regulatory developments

### For Deployers of High-Risk AI Systems

**Phase 1: Assessment and Planning (Months 1-3)**
- Inventory AI systems in use
- Identify high-risk systems
- Review provider instructions for use
- Conduct fundamental rights impact assessments
- Develop compliance plan

**Phase 2: Implementation (Months 4-12)**
- Assign human oversight personnel
- Provide training on AI systems and oversight responsibilities
- Establish monitoring procedures
- Implement record-keeping systems
- Document compliance measures

**Phase 3: Ongoing Compliance (Month 12+)**
- Monitor system operation
- Ensure effective human oversight
- Maintain logs
- Report incidents to providers and authorities
- Cooperate with authorities
- Review and update procedures regularly

### For GPAI Providers

**Phase 1: Assessment and Planning (Months 1-6)**
- Determine whether models are GPAI
- Assess whether models have systemic risk (compute threshold)
- Participate in codes of practice development
- Develop compliance roadmap

**Phase 2: Baseline Compliance (Months 7-18)**
- Create technical documentation
- Develop information packages for downstream providers
- Implement copyright compliance policy
- Prepare public training data summary

**Phase 3: Systemic Risk Compliance (Months 7-24, if applicable)**
- Establish model evaluation protocols
- Conduct adversarial testing
- Assess and mitigate systemic risks
- Implement incident tracking and reporting systems
- Enhance cybersecurity protections

**Phase 4: Ongoing Compliance (Month 24+)**
- Update documentation for new model versions
- Conduct regular model evaluations
- Monitor for serious incidents
- Engage with AI Office and other authorities
- Participate in codes of practice updates

## Resources and Next Steps

### Official Resources

**EU AI Act Text**: [EUR-Lex](https://eur-lex.europa.eu/) - Official EU legislation database

**European Commission AI Act Page**: Guidance, FAQs, and updates from the Commission

**AI Office**: Contact information and guidance (once operational)

**National Competent Authorities**: Each EU member state will publish contact information and national guidance

### Standards and Guidelines

**Harmonized Standards**: The European Commission will publish harmonized standards providing technical specifications for compliance. Following these standards creates a presumption of conformity.

**ISO/IEC Standards**: International standards for AI (ISO/IEC 42001, ISO/IEC 23894, etc.) may be referenced or harmonized.

**Codes of Practice**: GPAI providers will develop codes of practice providing practical compliance guidance.

### Professional Services

**Legal Counsel**: Engage lawyers specializing in EU AI regulation for legal interpretation and compliance strategy.

**Technical Consultants**: Work with AI experts to implement technical requirements (risk management, data governance, testing, etc.).

**Conformity Assessment Bodies**: Engage notified bodies for third-party conformity assessment (when required).

**Training Providers**: Utilize courses like this one to educate your team.

### Internal Actions

**Establish AI Governance**: Create organizational structures, policies, and procedures for AI development and deployment.

**Implement AI Ethics**: Develop ethical principles and practices complementing legal compliance.

**Engage Stakeholders**: Involve affected communities, users, and civil society in AI development and deployment decisions.

**Monitor Regulatory Developments**: Stay informed about guidance, standards, enforcement actions, and regulatory updates.

## Conclusion: The Path Forward

The EU AI Act represents a fundamental shift in how AI systems are developed, deployed, and governed. Compliance is not a one-time project but an ongoing commitment to responsible AI.

**Key principles for success**:

1. **Start now**: Don't wait for deadlines. The sooner you begin, the more manageable compliance becomes.

2. **Prioritize risks**: Focus first on prohibited practices (February 2, 2025 deadline), then high-risk systems (August 2, 2026 deadline).

3. **Build systematically**: Establish organization-wide systems (risk management, quality management, data governance) rather than addressing systems individually.

4. **Document everything**: Comprehensive documentation is essential for both compliance and demonstrating good faith efforts.

5. **Engage proactively**: Participate in codes of practice, industry working groups, and regulatory consultations to shape implementation.

6. **Embrace the opportunity**: The Act creates a competitive advantage for organizations that excel at responsible AI. Compliance is not just risk mitigation—it's a market differentiator.

**The EU AI Act is not just regulation—it's a vision for trustworthy AI that respects fundamental rights, promotes safety, and enables innovation within ethical boundaries.**

Your organization's response to this regulation will define your role in the AI-powered future. Will you be a leader in responsible AI, or will you struggle to catch up?

The choice—and the opportunity—is yours.

## Congratulations!

You've completed the **EU AI Act Fundamentals** course. You now understand:

✅ The Act's purpose, scope, and regulatory framework  
✅ Risk classification (prohibited, high-risk, limited-risk, minimal-risk)  
✅ Prohibited AI practices and their enforcement  
✅ High-risk AI systems across all eight Annex III categories  
✅ Provider and deployer obligations  
✅ Transparency requirements for all AI systems  
✅ GPAI regulation and governance structures  
✅ Compliance timelines, penalties, and enforcement  
✅ Practical steps for achieving compliance

**Next steps**:

1. **Apply your knowledge**: Conduct the immediate compliance actions outlined in this module.

2. **Continue learning**: Consider the **EU AI Act Advanced** course for deep dives into technical implementation, risk assessment methodologies, and sector-specific applications.

3. **Stay informed**: Subscribe to regulatory updates and engage with the AI governance community.

4. **Share your knowledge**: Educate colleagues and stakeholders about the Act's requirements and implications.

5. **Take the certification exam**: Demonstrate your mastery of EU AI Act fundamentals and earn your certificate.

**Thank you for investing in responsible AI. Your commitment to compliance and ethics will help build a future where AI benefits everyone.**

## Key Takeaways

✅ **Prohibited practices must be eliminated by February 2, 2025**—the first and most urgent deadline

✅ **Transparency obligations apply to all AI systems by August 2, 2025**

✅ **High-risk AI systems must comply by August 2, 2026**—the most significant deadline for most organizations

✅ **GPAI obligations take effect August 2, 2026**, with codes of practice due August 2, 2025

✅ **Existing high-risk systems have until August 2, 2027** to achieve compliance

✅ **Penalties are severe**: €35M/7% turnover (prohibited practices, GPAI), €15M/3% turnover (high-risk), €7.5M/1.5% turnover (information obligations)

✅ **Immediate actions**: Inventory AI systems, assess prohibited practices, classify high-risk systems, identify transparency obligations, assign responsibility, educate stakeholders

✅ **Compliance is ongoing**—not a one-time project but a continuous commitment to responsible AI

✅ **Start now**—the sooner you begin, the more manageable compliance becomes
