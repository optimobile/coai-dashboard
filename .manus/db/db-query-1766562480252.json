{
  "query": "INSERT INTO watchdog_reports (title, description, aiSystemName, companyName, incidentType, severity, status) VALUES \n('Gender bias detected in job recommendation AI', 'A user reported that a job recommendation system consistently shows higher-paying tech jobs to male users while showing administrative roles to female users with similar qualifications. Testing with controlled profiles showed a 40% wage gap in recommended positions based solely on gender indicators.', 'TechRecruit AI v3.2', 'TechRecruit Inc', 'bias', 'high', 'under_review'),\n('AI chatbot providing medical advice without disclaimer', 'A health-focused chatbot is providing specific medical diagnoses and treatment recommendations without proper disclaimers or suggestions to consult healthcare professionals. Multiple users have reported following AI advice instead of seeking professional medical help, with at least one case resulting in delayed treatment.', 'HealthBot Pro', 'HealthBot Inc', 'safety', 'critical', 'under_review'),\n('Privacy concern: AI assistant storing conversation history', 'Users discovered that an AI assistant is storing full conversation histories including sensitive personal information without clear consent or data retention policies. The data appears to be used for model training without explicit user opt-in.', 'AssistAI Personal', 'AssistAI Corp', 'privacy', 'medium', 'under_review'),\n('AI content moderation flagging legitimate news as misinformation', 'An AI-powered content moderation system is incorrectly flagging legitimate news articles from established outlets as misinformation. The system appears to have a bias against certain political viewpoints, affecting press freedom.', 'TruthGuard AI', 'SocialMedia Corp', 'misinformation', 'high', 'under_review'),\n('Facial recognition system showing racial bias in accuracy', 'A facial recognition system deployed at airport security shows significantly lower accuracy rates for individuals with darker skin tones. Error rates are 34% higher for Black individuals compared to white individuals, leading to disproportionate secondary screening.', 'SecureFace Pro', 'SecurityTech Ltd', 'bias', 'critical', 'under_review');",
  "command": "mysql --batch --raw --column-names --default-character-set=utf8mb4 --host gateway02.us-east-1.prod.aws.tidbcloud.com --port 4000 --user 3VC7xi4RHX81jG7.65112bc774d1 --database K34VNBtbDJyjtW8qhrCBdB --execute INSERT INTO watchdog_reports (title, description, aiSystemName, companyName, incidentType, severity, status) VALUES \n('Gender bias detected in job recommendation AI', 'A user reported that a job recommendation system consistently shows higher-paying tech jobs to male users while showing administrative roles to female users with similar qualifications. Testing with controlled profiles showed a 40% wage gap in recommended positions based solely on gender indicators.', 'TechRecruit AI v3.2', 'TechRecruit Inc', 'bias', 'high', 'under_review'),\n('AI chatbot providing medical advice without disclaimer', 'A health-focused chatbot is providing specific medical diagnoses and treatment recommendations without proper disclaimers or suggestions to consult healthcare professionals. Multiple users have reported following AI advice instead of seeking professional medical help, with at least one case resulting in delayed treatment.', 'HealthBot Pro', 'HealthBot Inc', 'safety', 'critical', 'under_review'),\n('Privacy concern: AI assistant storing conversation history', 'Users discovered that an AI assistant is storing full conversation histories including sensitive personal information without clear consent or data retention policies. The data appears to be used for model training without explicit user opt-in.', 'AssistAI Personal', 'AssistAI Corp', 'privacy', 'medium', 'under_review'),\n('AI content moderation flagging legitimate news as misinformation', 'An AI-powered content moderation system is incorrectly flagging legitimate news articles from established outlets as misinformation. The system appears to have a bias against certain political viewpoints, affecting press freedom.', 'TruthGuard AI', 'SocialMedia Corp', 'misinformation', 'high', 'under_review'),\n('Facial recognition system showing racial bias in accuracy', 'A facial recognition system deployed at airport security shows significantly lower accuracy rates for individuals with darker skin tones. Error rates are 34% higher for Black individuals compared to white individuals, leading to disproportionate secondary screening.', 'SecureFace Pro', 'SecurityTech Ltd', 'bias', 'critical', 'under_review');",
  "rows": [],
  "messages": [],
  "stdout": "",
  "stderr": "",
  "execution_time_ms": 66
}