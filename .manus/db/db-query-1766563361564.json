{
  "query": "INSERT INTO test_questions (testId, questionText, questionType, options, correctAnswer, explanation, points, difficulty, isActive) VALUES \n(1, 'What is the ''right to explanation'' in AI decision-making?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"The right to access AI source code\"},{\"id\":\"B\",\"text\":\"The right to understand how an automated decision affecting you was made\"},{\"id\":\"C\",\"text\":\"The right to modify AI algorithms\"},{\"id\":\"D\",\"text\":\"The right to use AI systems for free\"}]', 'B', 'The right to explanation gives individuals the right to receive meaningful information about the logic involved in automated decisions that significantly affect them, enabling them to understand and potentially contest such decisions.', 1, 'easy', true),\n(1, 'What is ''model card'' documentation in responsible AI?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"A physical card containing AI hardware specifications\"},{\"id\":\"B\",\"text\":\"Standardized documentation of model performance, limitations, and intended use\"},{\"id\":\"C\",\"text\":\"A credit card for purchasing AI services\"},{\"id\":\"D\",\"text\":\"A security access card for AI systems\"}]', 'B', 'Model cards are standardized documentation that accompanies AI models, describing their performance characteristics, intended use cases, limitations, ethical considerations, and evaluation results across different demographic groups.', 1, 'medium', true),\n(1, 'What is ''automation bias'' in human-AI interaction?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"Preference for manual processes over automation\"},{\"id\":\"B\",\"text\":\"Tendency to over-rely on automated systems and ignore contradicting information\"},{\"id\":\"C\",\"text\":\"Bias in how automation systems are programmed\"},{\"id\":\"D\",\"text\":\"Discrimination against automated workers\"}]', 'B', 'Automation bias is the tendency for humans to favor suggestions from automated systems, potentially ignoring contradicting information or failing to exercise appropriate oversight, which can lead to errors in high-stakes decisions.', 1, 'medium', true),\n(1, 'What is the first step a Watchdog Analyst should take when receiving a new incident report?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"Immediately escalate to the 33-Agent Council\"},{\"id\":\"B\",\"text\":\"Verify the report''s authenticity and gather initial context\"},{\"id\":\"C\",\"text\":\"Contact the AI company directly\"},{\"id\":\"D\",\"text\":\"Publish the report publicly\"}]', 'B', 'The first step is to verify the report''s authenticity and gather initial context, including checking for duplicate reports, verifying the AI system exists, and understanding the basic facts before proceeding with analysis.', 1, 'easy', true),\n(1, 'In the CSOAI framework, what triggers escalation to the 33-Agent Council?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"All reports are automatically escalated\"},{\"id\":\"B\",\"text\":\"Reports meeting severity thresholds or requiring multi-perspective analysis\"},{\"id\":\"C\",\"text\":\"Only reports from verified organizations\"},{\"id\":\"D\",\"text\":\"Reports older than 30 days\"}]', 'B', 'Reports are escalated to the 33-Agent Council when they meet severity thresholds (high/critical), involve complex multi-stakeholder impacts, or require diverse AI perspectives for comprehensive analysis.', 1, 'medium', true);",
  "command": "mysql --batch --raw --column-names --default-character-set=utf8mb4 --host gateway02.us-east-1.prod.aws.tidbcloud.com --port 4000 --user 3VC7xi4RHX81jG7.65112bc774d1 --database K34VNBtbDJyjtW8qhrCBdB --execute INSERT INTO test_questions (testId, questionText, questionType, options, correctAnswer, explanation, points, difficulty, isActive) VALUES \n(1, 'What is the ''right to explanation'' in AI decision-making?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"The right to access AI source code\"},{\"id\":\"B\",\"text\":\"The right to understand how an automated decision affecting you was made\"},{\"id\":\"C\",\"text\":\"The right to modify AI algorithms\"},{\"id\":\"D\",\"text\":\"The right to use AI systems for free\"}]', 'B', 'The right to explanation gives individuals the right to receive meaningful information about the logic involved in automated decisions that significantly affect them, enabling them to understand and potentially contest such decisions.', 1, 'easy', true),\n(1, 'What is ''model card'' documentation in responsible AI?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"A physical card containing AI hardware specifications\"},{\"id\":\"B\",\"text\":\"Standardized documentation of model performance, limitations, and intended use\"},{\"id\":\"C\",\"text\":\"A credit card for purchasing AI services\"},{\"id\":\"D\",\"text\":\"A security access card for AI systems\"}]', 'B', 'Model cards are standardized documentation that accompanies AI models, describing their performance characteristics, intended use cases, limitations, ethical considerations, and evaluation results across different demographic groups.', 1, 'medium', true),\n(1, 'What is ''automation bias'' in human-AI interaction?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"Preference for manual processes over automation\"},{\"id\":\"B\",\"text\":\"Tendency to over-rely on automated systems and ignore contradicting information\"},{\"id\":\"C\",\"text\":\"Bias in how automation systems are programmed\"},{\"id\":\"D\",\"text\":\"Discrimination against automated workers\"}]', 'B', 'Automation bias is the tendency for humans to favor suggestions from automated systems, potentially ignoring contradicting information or failing to exercise appropriate oversight, which can lead to errors in high-stakes decisions.', 1, 'medium', true),\n(1, 'What is the first step a Watchdog Analyst should take when receiving a new incident report?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"Immediately escalate to the 33-Agent Council\"},{\"id\":\"B\",\"text\":\"Verify the report''s authenticity and gather initial context\"},{\"id\":\"C\",\"text\":\"Contact the AI company directly\"},{\"id\":\"D\",\"text\":\"Publish the report publicly\"}]', 'B', 'The first step is to verify the report''s authenticity and gather initial context, including checking for duplicate reports, verifying the AI system exists, and understanding the basic facts before proceeding with analysis.', 1, 'easy', true),\n(1, 'In the CSOAI framework, what triggers escalation to the 33-Agent Council?', 'multiple_choice', '[{\"id\":\"A\",\"text\":\"All reports are automatically escalated\"},{\"id\":\"B\",\"text\":\"Reports meeting severity thresholds or requiring multi-perspective analysis\"},{\"id\":\"C\",\"text\":\"Only reports from verified organizations\"},{\"id\":\"D\",\"text\":\"Reports older than 30 days\"}]', 'B', 'Reports are escalated to the 33-Agent Council when they meet severity thresholds (high/critical), involve complex multi-stakeholder impacts, or require diverse AI perspectives for comprehensive analysis.', 1, 'medium', true);",
  "rows": [],
  "messages": [],
  "stdout": "",
  "stderr": "",
  "execution_time_ms": 71
}